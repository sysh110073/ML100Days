{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import Dropout\n",
    "def build_mlp(input_shape, output_units = 10, num_neurons=[512, 256, 128], drop_ratio = 0.2,\n",
    "              regularizer = l1, regularizer_ratio = 0.5):\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i ==0:\n",
    "            x = keras.layers.Dense(units = n_units,\n",
    "                                   activation = 'relu',\n",
    "                                   name = 'hidden_layer' + str(i+1),\n",
    "                                   kernel_regularizer=regularizer(regularizer_ratio))(input_layer)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units = n_units,\n",
    "                                  activation = 'relu',\n",
    "                                  name = 'hidden_layer' + str(i+1),\n",
    "                                  kernel_regularizer=regularizer(regularizer_ratio))(x)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "        \n",
    "    out = keras.layers.Dense(units = output_units, activation = 'softmax', name = 'output')(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "MOMENTUM = 0.95\n",
    "\n",
    "Batch_size = [32, 128, 256]\n",
    "Drop_ratio = [0.25,0.1,0.5,0.7]\n",
    "Regularizer_Function = [l1, l2]\n",
    "Regularizer_Ratio = [1e-2, 1e-4, 1e-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 9.5527 - accuracy: 0.0985 - val_loss: 4.4280 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4278 - accuracy: 0.0969 - val_loss: 4.4245 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4279 - accuracy: 0.0988 - val_loss: 4.4180 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.4279 - accuracy: 0.0970 - val_loss: 4.4299 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4278 - accuracy: 0.0984 - val_loss: 4.4350 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4278 - accuracy: 0.1004 - val_loss: 4.4408 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4277 - accuracy: 0.0993 - val_loss: 4.4336 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4277 - accuracy: 0.0987 - val_loss: 4.4245 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4276 - accuracy: 0.0980 - val_loss: 4.4156 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.4276 - accuracy: 0.0967 - val_loss: 4.4243 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4274 - accuracy: 0.0962 - val_loss: 4.4298 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.4273 - accuracy: 0.0994 - val_loss: 4.4312 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4273 - accuracy: 0.0999 - val_loss: 4.4262 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4273 - accuracy: 0.0973 - val_loss: 4.4230 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4272 - accuracy: 0.0972 - val_loss: 4.4219 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4272 - accuracy: 0.0982 - val_loss: 4.4274 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4271 - accuracy: 0.0997 - val_loss: 4.4350 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4270 - accuracy: 0.0996 - val_loss: 4.4295 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4269 - accuracy: 0.0964 - val_loss: 4.4238 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4269 - accuracy: 0.0973 - val_loss: 4.4146 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.8254 - accuracy: 0.2182 - val_loss: 2.1645 - val_accuracy: 0.3047\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1614 - accuracy: 0.2739 - val_loss: 2.0420 - val_accuracy: 0.3129\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.0646 - accuracy: 0.2907 - val_loss: 1.9586 - val_accuracy: 0.3420\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.0380 - accuracy: 0.2976 - val_loss: 1.9970 - val_accuracy: 0.3142\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0263 - accuracy: 0.3042 - val_loss: 1.9333 - val_accuracy: 0.3675\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0215 - accuracy: 0.3102 - val_loss: 1.9863 - val_accuracy: 0.3341\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0288 - accuracy: 0.3042 - val_loss: 1.9731 - val_accuracy: 0.3170\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.0170 - accuracy: 0.3089 - val_loss: 1.9717 - val_accuracy: 0.3398\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.0089 - accuracy: 0.3152 - val_loss: 1.9893 - val_accuracy: 0.3448\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.0060 - accuracy: 0.3172 - val_loss: 1.9279 - val_accuracy: 0.3643\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0026 - accuracy: 0.3190 - val_loss: 1.9039 - val_accuracy: 0.3718\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9993 - accuracy: 0.3183 - val_loss: 1.8890 - val_accuracy: 0.3831\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.0018 - accuracy: 0.3167 - val_loss: 1.9171 - val_accuracy: 0.3633\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.0002 - accuracy: 0.3171 - val_loss: 1.9182 - val_accuracy: 0.3595\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.9984 - accuracy: 0.3196 - val_loss: 1.8938 - val_accuracy: 0.3751\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.9997 - accuracy: 0.3217 - val_loss: 1.8966 - val_accuracy: 0.3643\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.0075 - accuracy: 0.3150 - val_loss: 1.9083 - val_accuracy: 0.3773\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.9970 - accuracy: 0.3229 - val_loss: 1.9160 - val_accuracy: 0.3548\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.9921 - accuracy: 0.3206 - val_loss: 1.9158 - val_accuracy: 0.3731\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9895 - accuracy: 0.3268 - val_loss: 1.9986 - val_accuracy: 0.3500\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 17s 10ms/step - loss: 2.0553 - accuracy: 0.2303 - val_loss: 1.8906 - val_accuracy: 0.3045\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9225 - accuracy: 0.2884 - val_loss: 1.8434 - val_accuracy: 0.3415\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8899 - accuracy: 0.3057 - val_loss: 1.8588 - val_accuracy: 0.3380\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8681 - accuracy: 0.3153 - val_loss: 1.7867 - val_accuracy: 0.3530\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.8550 - accuracy: 0.3240 - val_loss: 1.7605 - val_accuracy: 0.3804\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.8422 - accuracy: 0.3305 - val_loss: 1.7552 - val_accuracy: 0.3767\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8267 - accuracy: 0.3331 - val_loss: 1.7773 - val_accuracy: 0.3688\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8194 - accuracy: 0.3355 - val_loss: 1.7160 - val_accuracy: 0.3840\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8117 - accuracy: 0.3415 - val_loss: 1.7250 - val_accuracy: 0.3843\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8085 - accuracy: 0.3415 - val_loss: 1.7299 - val_accuracy: 0.3881\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8015 - accuracy: 0.3438 - val_loss: 1.7257 - val_accuracy: 0.3903\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7998 - accuracy: 0.3455 - val_loss: 1.7055 - val_accuracy: 0.3859\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7901 - accuracy: 0.3512 - val_loss: 1.6962 - val_accuracy: 0.3930\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7917 - accuracy: 0.3510 - val_loss: 1.7252 - val_accuracy: 0.3896\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7824 - accuracy: 0.3542 - val_loss: 1.6955 - val_accuracy: 0.3948\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7807 - accuracy: 0.3547 - val_loss: 1.6898 - val_accuracy: 0.4034\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7754 - accuracy: 0.3542 - val_loss: 1.6931 - val_accuracy: 0.3919\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7755 - accuracy: 0.3560 - val_loss: 1.7095 - val_accuracy: 0.4042\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7658 - accuracy: 0.3596 - val_loss: 1.6791 - val_accuracy: 0.4036\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7687 - accuracy: 0.3581 - val_loss: 1.6713 - val_accuracy: 0.4116\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.8022 - accuracy: 0.2128 - val_loss: 2.1346 - val_accuracy: 0.2466\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1302 - accuracy: 0.2292 - val_loss: 2.0534 - val_accuracy: 0.2511\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.1193 - accuracy: 0.2233 - val_loss: 2.0437 - val_accuracy: 0.2729\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.1048 - accuracy: 0.2244 - val_loss: 2.1030 - val_accuracy: 0.2092\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1068 - accuracy: 0.2276 - val_loss: 2.0445 - val_accuracy: 0.2587\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0947 - accuracy: 0.2309 - val_loss: 2.0530 - val_accuracy: 0.2704\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0896 - accuracy: 0.2339 - val_loss: 2.0442 - val_accuracy: 0.2574\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1065 - accuracy: 0.2181 - val_loss: 2.0377 - val_accuracy: 0.2555\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0913 - accuracy: 0.2255 - val_loss: 2.0153 - val_accuracy: 0.2569\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0986 - accuracy: 0.2196 - val_loss: 2.0304 - val_accuracy: 0.2408\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1158 - accuracy: 0.2109 - val_loss: 2.0200 - val_accuracy: 0.2508\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1041 - accuracy: 0.2191 - val_loss: 2.0730 - val_accuracy: 0.2289\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1103 - accuracy: 0.2136 - val_loss: 2.1363 - val_accuracy: 0.2275\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1009 - accuracy: 0.2165 - val_loss: 2.0560 - val_accuracy: 0.2212\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1133 - accuracy: 0.2117 - val_loss: 2.1210 - val_accuracy: 0.2122\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1286 - accuracy: 0.1983 - val_loss: 2.0444 - val_accuracy: 0.2446\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1281 - accuracy: 0.1982 - val_loss: 2.1573 - val_accuracy: 0.1836\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1280 - accuracy: 0.1994 - val_loss: 2.0632 - val_accuracy: 0.2244\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1258 - accuracy: 0.2009 - val_loss: 2.0705 - val_accuracy: 0.2339\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1304 - accuracy: 0.1983 - val_loss: 2.0544 - val_accuracy: 0.2334\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1249 - accuracy: 0.2337 - val_loss: 1.9291 - val_accuracy: 0.3298\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9598 - accuracy: 0.2890 - val_loss: 1.8838 - val_accuracy: 0.3458\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.9194 - accuracy: 0.3010 - val_loss: 1.8216 - val_accuracy: 0.3556\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8964 - accuracy: 0.3136 - val_loss: 1.8154 - val_accuracy: 0.3582\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8798 - accuracy: 0.3196 - val_loss: 1.7781 - val_accuracy: 0.3773\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8660 - accuracy: 0.3287 - val_loss: 1.7664 - val_accuracy: 0.3834\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8574 - accuracy: 0.3316 - val_loss: 1.8200 - val_accuracy: 0.3682\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8495 - accuracy: 0.3372 - val_loss: 1.7555 - val_accuracy: 0.3905\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8452 - accuracy: 0.3417 - val_loss: 1.7591 - val_accuracy: 0.3944\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8378 - accuracy: 0.3448 - val_loss: 1.7234 - val_accuracy: 0.4076\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8352 - accuracy: 0.3439 - val_loss: 1.8121 - val_accuracy: 0.3493\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8351 - accuracy: 0.3455 - val_loss: 1.7980 - val_accuracy: 0.3812\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8298 - accuracy: 0.3474 - val_loss: 1.7441 - val_accuracy: 0.3864\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8331 - accuracy: 0.3475 - val_loss: 1.7656 - val_accuracy: 0.3799\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8262 - accuracy: 0.3492 - val_loss: 1.7245 - val_accuracy: 0.4078\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8298 - accuracy: 0.3494 - val_loss: 1.7529 - val_accuracy: 0.3915\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8233 - accuracy: 0.3540 - val_loss: 1.7600 - val_accuracy: 0.3840\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8175 - accuracy: 0.3528 - val_loss: 1.7567 - val_accuracy: 0.3936\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8181 - accuracy: 0.3530 - val_loss: 1.7417 - val_accuracy: 0.4028\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8171 - accuracy: 0.3538 - val_loss: 1.7661 - val_accuracy: 0.3913\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0592 - accuracy: 0.2225 - val_loss: 1.8940 - val_accuracy: 0.2995\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9413 - accuracy: 0.2743 - val_loss: 1.8515 - val_accuracy: 0.3290\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9162 - accuracy: 0.2868 - val_loss: 1.8418 - val_accuracy: 0.3312\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8989 - accuracy: 0.2967 - val_loss: 1.8184 - val_accuracy: 0.3504\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8835 - accuracy: 0.3074 - val_loss: 1.8359 - val_accuracy: 0.3431\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8614 - accuracy: 0.3161 - val_loss: 1.7676 - val_accuracy: 0.3732\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8460 - accuracy: 0.3251 - val_loss: 1.7395 - val_accuracy: 0.3773\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8382 - accuracy: 0.3241 - val_loss: 1.7765 - val_accuracy: 0.3636\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8238 - accuracy: 0.3324 - val_loss: 1.7432 - val_accuracy: 0.3707\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8154 - accuracy: 0.3358 - val_loss: 1.7464 - val_accuracy: 0.3720\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8106 - accuracy: 0.3370 - val_loss: 1.7165 - val_accuracy: 0.3825\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 1.8067 - accuracy: 0.3405 - val_loss: 1.8110 - val_accuracy: 0.3508\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7978 - accuracy: 0.3451 - val_loss: 1.7127 - val_accuracy: 0.3890\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7931 - accuracy: 0.3462 - val_loss: 1.7506 - val_accuracy: 0.3747\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7891 - accuracy: 0.3498 - val_loss: 1.7168 - val_accuracy: 0.3962\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7861 - accuracy: 0.3522 - val_loss: 1.7244 - val_accuracy: 0.3960\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7859 - accuracy: 0.3522 - val_loss: 1.6867 - val_accuracy: 0.3995\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7761 - accuracy: 0.3538 - val_loss: 1.6898 - val_accuracy: 0.3936\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7744 - accuracy: 0.3575 - val_loss: 1.7020 - val_accuracy: 0.3939\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.7721 - accuracy: 0.3570 - val_loss: 1.6840 - val_accuracy: 0.4100\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 9.4723 - accuracy: 0.0998 - val_loss: 4.4244 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4233 - accuracy: 0.1005 - val_loss: 4.4193 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.4235 - accuracy: 0.0992 - val_loss: 4.4162 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4235 - accuracy: 0.0988 - val_loss: 4.4251 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 4.4234 - accuracy: 0.0984 - val_loss: 4.4298 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4233 - accuracy: 0.0975 - val_loss: 4.4338 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4232 - accuracy: 0.0983 - val_loss: 4.4286 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4232 - accuracy: 0.0984 - val_loss: 4.4178 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4232 - accuracy: 0.0982 - val_loss: 4.4151 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4231 - accuracy: 0.0980 - val_loss: 4.4185 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 4.4230 - accuracy: 0.0959 - val_loss: 4.4278 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 4.4229 - accuracy: 0.0959 - val_loss: 4.4253 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 4.4229 - accuracy: 0.0964 - val_loss: 4.4243 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4228 - accuracy: 0.0990 - val_loss: 4.4194 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4228 - accuracy: 0.0966 - val_loss: 4.4167 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 4.4227 - accuracy: 0.1004 - val_loss: 4.4226 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 4.4227 - accuracy: 0.0988 - val_loss: 4.4317 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4226 - accuracy: 0.0997 - val_loss: 4.4226 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4225 - accuracy: 0.0977 - val_loss: 4.4207 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.4225 - accuracy: 0.0981 - val_loss: 4.4093 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.6412 - accuracy: 0.2787 - val_loss: 2.0841 - val_accuracy: 0.3468\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 2.0626 - accuracy: 0.3271 - val_loss: 1.9482 - val_accuracy: 0.3495\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.9665 - accuracy: 0.3507 - val_loss: 1.9275 - val_accuracy: 0.3548\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.9335 - accuracy: 0.3544 - val_loss: 1.8500 - val_accuracy: 0.3935\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9109 - accuracy: 0.3633 - val_loss: 1.8302 - val_accuracy: 0.4016\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8927 - accuracy: 0.3732 - val_loss: 1.8353 - val_accuracy: 0.4044\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8914 - accuracy: 0.3727 - val_loss: 1.8389 - val_accuracy: 0.3927\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8842 - accuracy: 0.3765 - val_loss: 1.7948 - val_accuracy: 0.4224\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8714 - accuracy: 0.3807 - val_loss: 1.7805 - val_accuracy: 0.4208\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8776 - accuracy: 0.3801 - val_loss: 1.8590 - val_accuracy: 0.4020\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8634 - accuracy: 0.3846 - val_loss: 1.7616 - val_accuracy: 0.4288\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8699 - accuracy: 0.3860 - val_loss: 1.8378 - val_accuracy: 0.3984\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8683 - accuracy: 0.3843 - val_loss: 1.8142 - val_accuracy: 0.4053\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8555 - accuracy: 0.3888 - val_loss: 1.8203 - val_accuracy: 0.4073\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8565 - accuracy: 0.3905 - val_loss: 1.7886 - val_accuracy: 0.4188\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8532 - accuracy: 0.3929 - val_loss: 1.8035 - val_accuracy: 0.4189\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8547 - accuracy: 0.3898 - val_loss: 1.7552 - val_accuracy: 0.4350\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8467 - accuracy: 0.3952 - val_loss: 1.7885 - val_accuracy: 0.4228\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.8465 - accuracy: 0.3959 - val_loss: 1.7612 - val_accuracy: 0.4341\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8438 - accuracy: 0.3967 - val_loss: 1.7616 - val_accuracy: 0.4301\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9369 - accuracy: 0.2912 - val_loss: 1.8072 - val_accuracy: 0.3520\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7827 - accuracy: 0.3566 - val_loss: 1.7192 - val_accuracy: 0.3876\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7242 - accuracy: 0.3796 - val_loss: 1.6738 - val_accuracy: 0.4052\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6902 - accuracy: 0.3904 - val_loss: 1.6265 - val_accuracy: 0.4140\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6638 - accuracy: 0.4011 - val_loss: 1.5748 - val_accuracy: 0.4355\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6462 - accuracy: 0.4074 - val_loss: 1.5612 - val_accuracy: 0.4447\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6300 - accuracy: 0.4119 - val_loss: 1.5933 - val_accuracy: 0.4367\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6143 - accuracy: 0.4193 - val_loss: 1.5571 - val_accuracy: 0.4454\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6082 - accuracy: 0.4217 - val_loss: 1.5586 - val_accuracy: 0.4442\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.5961 - accuracy: 0.4257 - val_loss: 1.5469 - val_accuracy: 0.4424\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5885 - accuracy: 0.4276 - val_loss: 1.5242 - val_accuracy: 0.4517\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5728 - accuracy: 0.4332 - val_loss: 1.5374 - val_accuracy: 0.4472\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5679 - accuracy: 0.4340 - val_loss: 1.5442 - val_accuracy: 0.4470\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5598 - accuracy: 0.4391 - val_loss: 1.5284 - val_accuracy: 0.4548\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5530 - accuracy: 0.4408 - val_loss: 1.5506 - val_accuracy: 0.4460\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5480 - accuracy: 0.4422 - val_loss: 1.5148 - val_accuracy: 0.4645\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5422 - accuracy: 0.4460 - val_loss: 1.5235 - val_accuracy: 0.4596\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5349 - accuracy: 0.4470 - val_loss: 1.4828 - val_accuracy: 0.4708\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5278 - accuracy: 0.4519 - val_loss: 1.4995 - val_accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5233 - accuracy: 0.4521 - val_loss: 1.4936 - val_accuracy: 0.4661\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.6517 - accuracy: 0.2482 - val_loss: 1.9960 - val_accuracy: 0.3125\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.0571 - accuracy: 0.2829 - val_loss: 1.9689 - val_accuracy: 0.3124\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0436 - accuracy: 0.2834 - val_loss: 2.0171 - val_accuracy: 0.3064\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0352 - accuracy: 0.2788 - val_loss: 1.9480 - val_accuracy: 0.3292\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0199 - accuracy: 0.2907 - val_loss: 1.9553 - val_accuracy: 0.3234\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0217 - accuracy: 0.2929 - val_loss: 1.9312 - val_accuracy: 0.3292\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0119 - accuracy: 0.2911 - val_loss: 1.9534 - val_accuracy: 0.3136\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0117 - accuracy: 0.2900 - val_loss: 2.0053 - val_accuracy: 0.2777\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0209 - accuracy: 0.2904 - val_loss: 2.0137 - val_accuracy: 0.2859\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.0144 - accuracy: 0.2920 - val_loss: 2.0150 - val_accuracy: 0.2844\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.0118 - accuracy: 0.2920 - val_loss: 1.9613 - val_accuracy: 0.3181\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0071 - accuracy: 0.2946 - val_loss: 1.9643 - val_accuracy: 0.3126\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0026 - accuracy: 0.2956 - val_loss: 1.9502 - val_accuracy: 0.3083\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0072 - accuracy: 0.2954 - val_loss: 1.9347 - val_accuracy: 0.3178\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9990 - accuracy: 0.2978 - val_loss: 1.9518 - val_accuracy: 0.3201\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0038 - accuracy: 0.2946 - val_loss: 1.9473 - val_accuracy: 0.3278\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.0025 - accuracy: 0.2947 - val_loss: 1.9547 - val_accuracy: 0.3197\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.9987 - accuracy: 0.2961 - val_loss: 1.9168 - val_accuracy: 0.3320\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0017 - accuracy: 0.2948 - val_loss: 2.0148 - val_accuracy: 0.2693\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9968 - accuracy: 0.2974 - val_loss: 1.9318 - val_accuracy: 0.3222\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0167 - accuracy: 0.2880 - val_loss: 1.8411 - val_accuracy: 0.3524\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8348 - accuracy: 0.3476 - val_loss: 1.7485 - val_accuracy: 0.3798\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7765 - accuracy: 0.3733 - val_loss: 1.7070 - val_accuracy: 0.3979\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7382 - accuracy: 0.3856 - val_loss: 1.6480 - val_accuracy: 0.4286\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7153 - accuracy: 0.3939 - val_loss: 1.6676 - val_accuracy: 0.4069\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6938 - accuracy: 0.4067 - val_loss: 1.6077 - val_accuracy: 0.4361\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6827 - accuracy: 0.4076 - val_loss: 1.6122 - val_accuracy: 0.4416\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6711 - accuracy: 0.4156 - val_loss: 1.6132 - val_accuracy: 0.4418\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6620 - accuracy: 0.4213 - val_loss: 1.6188 - val_accuracy: 0.4369\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6580 - accuracy: 0.4235 - val_loss: 1.6139 - val_accuracy: 0.4414\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6516 - accuracy: 0.4251 - val_loss: 1.5726 - val_accuracy: 0.4650\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6434 - accuracy: 0.4306 - val_loss: 1.6284 - val_accuracy: 0.4402\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6382 - accuracy: 0.4297 - val_loss: 1.5948 - val_accuracy: 0.4502\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6373 - accuracy: 0.4369 - val_loss: 1.5851 - val_accuracy: 0.4572\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6294 - accuracy: 0.4393 - val_loss: 1.5731 - val_accuracy: 0.4626\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6271 - accuracy: 0.4412 - val_loss: 1.6133 - val_accuracy: 0.4487\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6239 - accuracy: 0.4410 - val_loss: 1.5780 - val_accuracy: 0.4654\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6173 - accuracy: 0.4465 - val_loss: 1.5827 - val_accuracy: 0.4578\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6160 - accuracy: 0.4446 - val_loss: 1.5831 - val_accuracy: 0.4562\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.6159 - accuracy: 0.4466 - val_loss: 1.5852 - val_accuracy: 0.4560\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9540 - accuracy: 0.2851 - val_loss: 1.7751 - val_accuracy: 0.3529\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.7909 - accuracy: 0.3500 - val_loss: 1.6942 - val_accuracy: 0.3916\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7367 - accuracy: 0.3743 - val_loss: 1.6706 - val_accuracy: 0.4018\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.7002 - accuracy: 0.3892 - val_loss: 1.6084 - val_accuracy: 0.4239\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6761 - accuracy: 0.3952 - val_loss: 1.6120 - val_accuracy: 0.4151\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6548 - accuracy: 0.4053 - val_loss: 1.6233 - val_accuracy: 0.4140\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6425 - accuracy: 0.4093 - val_loss: 1.5850 - val_accuracy: 0.4339\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 1.6281 - accuracy: 0.4157 - val_loss: 1.5676 - val_accuracy: 0.4371\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.6097 - accuracy: 0.4215 - val_loss: 1.5345 - val_accuracy: 0.4540\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5963 - accuracy: 0.4249 - val_loss: 1.5478 - val_accuracy: 0.4451\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5885 - accuracy: 0.4263 - val_loss: 1.5668 - val_accuracy: 0.4396\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5768 - accuracy: 0.4338 - val_loss: 1.5368 - val_accuracy: 0.4523\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5679 - accuracy: 0.4369 - val_loss: 1.5528 - val_accuracy: 0.4473\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5654 - accuracy: 0.4372 - val_loss: 1.5484 - val_accuracy: 0.4408\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5537 - accuracy: 0.4405 - val_loss: 1.5225 - val_accuracy: 0.4565\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5523 - accuracy: 0.4439 - val_loss: 1.5146 - val_accuracy: 0.4587\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5430 - accuracy: 0.4468 - val_loss: 1.5427 - val_accuracy: 0.4466\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5339 - accuracy: 0.4486 - val_loss: 1.5471 - val_accuracy: 0.4554\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5346 - accuracy: 0.4471 - val_loss: 1.5066 - val_accuracy: 0.4620\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5284 - accuracy: 0.4499 - val_loss: 1.4907 - val_accuracy: 0.4686\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 10.1047 - accuracy: 0.0991 - val_loss: 4.3647 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3674 - accuracy: 0.0973 - val_loss: 4.3664 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3682 - accuracy: 0.1002 - val_loss: 4.3662 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3683 - accuracy: 0.0987 - val_loss: 4.3694 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3683 - accuracy: 0.0977 - val_loss: 4.3703 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3682 - accuracy: 0.0998 - val_loss: 4.3699 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3682 - accuracy: 0.0980 - val_loss: 4.3665 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3682 - accuracy: 0.0990 - val_loss: 4.3679 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3681 - accuracy: 0.0971 - val_loss: 4.3668 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3680 - accuracy: 0.1004 - val_loss: 4.3693 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3680 - accuracy: 0.0983 - val_loss: 4.3685 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3680 - accuracy: 0.0997 - val_loss: 4.3670 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3679 - accuracy: 0.0971 - val_loss: 4.3664 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3679 - accuracy: 0.0990 - val_loss: 4.3652 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3678 - accuracy: 0.0988 - val_loss: 4.3646 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3678 - accuracy: 0.0979 - val_loss: 4.3662 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3677 - accuracy: 0.1011 - val_loss: 4.3686 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3677 - accuracy: 0.0995 - val_loss: 4.3670 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.3677 - accuracy: 0.0991 - val_loss: 4.3661 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3676 - accuracy: 0.0987 - val_loss: 4.3651 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 3.0699 - accuracy: 0.1439 - val_loss: 2.3531 - val_accuracy: 0.1797\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.3387 - accuracy: 0.1672 - val_loss: 2.2108 - val_accuracy: 0.2203\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2305 - accuracy: 0.1768 - val_loss: 2.1805 - val_accuracy: 0.2377\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1990 - accuracy: 0.1795 - val_loss: 2.1313 - val_accuracy: 0.2233\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1868 - accuracy: 0.1839 - val_loss: 2.1462 - val_accuracy: 0.2287\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1814 - accuracy: 0.1911 - val_loss: 2.1415 - val_accuracy: 0.2224\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1782 - accuracy: 0.1877 - val_loss: 2.0726 - val_accuracy: 0.2531\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1765 - accuracy: 0.1916 - val_loss: 2.1442 - val_accuracy: 0.2099\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1809 - accuracy: 0.1913 - val_loss: 2.1689 - val_accuracy: 0.2138\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1747 - accuracy: 0.1940 - val_loss: 2.1131 - val_accuracy: 0.2138\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1739 - accuracy: 0.1971 - val_loss: 2.1273 - val_accuracy: 0.2245\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1726 - accuracy: 0.1968 - val_loss: 2.1406 - val_accuracy: 0.2057\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1730 - accuracy: 0.1968 - val_loss: 2.1312 - val_accuracy: 0.2351\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1659 - accuracy: 0.1993 - val_loss: 2.0960 - val_accuracy: 0.2303\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1751 - accuracy: 0.1968 - val_loss: 2.0871 - val_accuracy: 0.2628\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1764 - accuracy: 0.1976 - val_loss: 2.0872 - val_accuracy: 0.2427\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1746 - accuracy: 0.1969 - val_loss: 2.1346 - val_accuracy: 0.2046\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1673 - accuracy: 0.2009 - val_loss: 2.1070 - val_accuracy: 0.2205\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1710 - accuracy: 0.2002 - val_loss: 2.1009 - val_accuracy: 0.2220\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1742 - accuracy: 0.2006 - val_loss: 2.1350 - val_accuracy: 0.1950\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.2534 - accuracy: 0.1278 - val_loss: 2.1690 - val_accuracy: 0.1780\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.2034 - accuracy: 0.1385 - val_loss: 2.0947 - val_accuracy: 0.1847\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1757 - accuracy: 0.1500 - val_loss: 2.1448 - val_accuracy: 0.1750\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1675 - accuracy: 0.1523 - val_loss: 2.0712 - val_accuracy: 0.1843\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1601 - accuracy: 0.1524 - val_loss: 2.1031 - val_accuracy: 0.1895\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1582 - accuracy: 0.1593 - val_loss: 2.1127 - val_accuracy: 0.1816\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1602 - accuracy: 0.1543 - val_loss: 2.0841 - val_accuracy: 0.1874\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1570 - accuracy: 0.1560 - val_loss: 2.0774 - val_accuracy: 0.1783\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1567 - accuracy: 0.1582 - val_loss: 2.1161 - val_accuracy: 0.1923\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1548 - accuracy: 0.1596 - val_loss: 2.0826 - val_accuracy: 0.1742\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1572 - accuracy: 0.1645 - val_loss: 2.0838 - val_accuracy: 0.1917\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1584 - accuracy: 0.1612 - val_loss: 2.0735 - val_accuracy: 0.2027\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1579 - accuracy: 0.1626 - val_loss: 2.0752 - val_accuracy: 0.1945\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1604 - accuracy: 0.1595 - val_loss: 2.0606 - val_accuracy: 0.2079\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1501 - accuracy: 0.1706 - val_loss: 2.1350 - val_accuracy: 0.1910\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1376 - accuracy: 0.1766 - val_loss: 2.0698 - val_accuracy: 0.2187\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1403 - accuracy: 0.1769 - val_loss: 2.0802 - val_accuracy: 0.1920\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.1272 - accuracy: 0.1815 - val_loss: 2.1009 - val_accuracy: 0.1988\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1318 - accuracy: 0.1808 - val_loss: 2.0527 - val_accuracy: 0.2151\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1437 - accuracy: 0.1758 - val_loss: 2.0950 - val_accuracy: 0.2030\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 3.1492 - accuracy: 0.1371 - val_loss: 2.1842 - val_accuracy: 0.1829\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2409 - accuracy: 0.1341 - val_loss: 2.1434 - val_accuracy: 0.1853\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2359 - accuracy: 0.1389 - val_loss: 2.2025 - val_accuracy: 0.1850\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2305 - accuracy: 0.1408 - val_loss: 2.1421 - val_accuracy: 0.1882\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2250 - accuracy: 0.1494 - val_loss: 2.1617 - val_accuracy: 0.1818\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2360 - accuracy: 0.1424 - val_loss: 2.1956 - val_accuracy: 0.1806\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2279 - accuracy: 0.1437 - val_loss: 2.2043 - val_accuracy: 0.1817\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2350 - accuracy: 0.1400 - val_loss: 2.1286 - val_accuracy: 0.1853\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2274 - accuracy: 0.1460 - val_loss: 2.1391 - val_accuracy: 0.1892\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2318 - accuracy: 0.1393 - val_loss: 2.1624 - val_accuracy: 0.1918\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2363 - accuracy: 0.1417 - val_loss: 2.1078 - val_accuracy: 0.1866\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2223 - accuracy: 0.1514 - val_loss: 2.1412 - val_accuracy: 0.1825\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2267 - accuracy: 0.1494 - val_loss: 2.1725 - val_accuracy: 0.1717\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2380 - accuracy: 0.1525 - val_loss: 2.2202 - val_accuracy: 0.1672\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2413 - accuracy: 0.1494 - val_loss: 2.1787 - val_accuracy: 0.1804\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2335 - accuracy: 0.1515 - val_loss: 2.1628 - val_accuracy: 0.1801\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2326 - accuracy: 0.1531 - val_loss: 2.1566 - val_accuracy: 0.1869\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2292 - accuracy: 0.1549 - val_loss: 2.1673 - val_accuracy: 0.1773\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2299 - accuracy: 0.1553 - val_loss: 2.2235 - val_accuracy: 0.1599\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.2372 - accuracy: 0.1520 - val_loss: 2.1443 - val_accuracy: 0.1797\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3149 - accuracy: 0.1456 - val_loss: 2.1593 - val_accuracy: 0.1951\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.2012 - accuracy: 0.1620 - val_loss: 2.1069 - val_accuracy: 0.2392\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1677 - accuracy: 0.1685 - val_loss: 2.0896 - val_accuracy: 0.2367\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1483 - accuracy: 0.1769 - val_loss: 2.1171 - val_accuracy: 0.2256\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1364 - accuracy: 0.1804 - val_loss: 2.1140 - val_accuracy: 0.2248\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1410 - accuracy: 0.1778 - val_loss: 2.0707 - val_accuracy: 0.2145\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1751 - accuracy: 0.1618 - val_loss: 2.0906 - val_accuracy: 0.2034\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1558 - accuracy: 0.1707 - val_loss: 2.0490 - val_accuracy: 0.2219\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1276 - accuracy: 0.1785 - val_loss: 2.0655 - val_accuracy: 0.2133\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1282 - accuracy: 0.1801 - val_loss: 2.0946 - val_accuracy: 0.2331\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1241 - accuracy: 0.1857 - val_loss: 2.1418 - val_accuracy: 0.1920\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1174 - accuracy: 0.1854 - val_loss: 2.2501 - val_accuracy: 0.1605\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1168 - accuracy: 0.1881 - val_loss: 2.2262 - val_accuracy: 0.1795\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1205 - accuracy: 0.1829 - val_loss: 2.1319 - val_accuracy: 0.1892\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1141 - accuracy: 0.1906 - val_loss: 2.1680 - val_accuracy: 0.1840\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1143 - accuracy: 0.1889 - val_loss: 2.0984 - val_accuracy: 0.1836\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1158 - accuracy: 0.1883 - val_loss: 2.1807 - val_accuracy: 0.1875\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1148 - accuracy: 0.1897 - val_loss: 2.1265 - val_accuracy: 0.2138\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.1253 - accuracy: 0.1879 - val_loss: 2.0747 - val_accuracy: 0.2306\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1630 - accuracy: 0.1774 - val_loss: 2.0938 - val_accuracy: 0.2002\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.2705 - accuracy: 0.1293 - val_loss: 2.1687 - val_accuracy: 0.1580\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2339 - accuracy: 0.1351 - val_loss: 2.1533 - val_accuracy: 0.1884\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.2317 - accuracy: 0.1351 - val_loss: 2.2050 - val_accuracy: 0.1641\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2287 - accuracy: 0.1358 - val_loss: 2.1575 - val_accuracy: 0.1858\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2269 - accuracy: 0.1358 - val_loss: 2.1524 - val_accuracy: 0.1925\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2235 - accuracy: 0.1378 - val_loss: 2.1629 - val_accuracy: 0.1703\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2256 - accuracy: 0.1357 - val_loss: 2.1850 - val_accuracy: 0.1591\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2221 - accuracy: 0.1364 - val_loss: 2.1445 - val_accuracy: 0.1670\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2258 - accuracy: 0.1361 - val_loss: 2.1687 - val_accuracy: 0.1733\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2208 - accuracy: 0.1371 - val_loss: 2.2309 - val_accuracy: 0.1394\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2243 - accuracy: 0.1378 - val_loss: 2.2078 - val_accuracy: 0.1501\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2180 - accuracy: 0.1400 - val_loss: 2.1608 - val_accuracy: 0.1786\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2207 - accuracy: 0.1404 - val_loss: 2.1413 - val_accuracy: 0.1790\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2208 - accuracy: 0.1395 - val_loss: 2.1481 - val_accuracy: 0.1830\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2214 - accuracy: 0.1372 - val_loss: 2.1418 - val_accuracy: 0.1798\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2215 - accuracy: 0.1391 - val_loss: 2.1773 - val_accuracy: 0.1636\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2187 - accuracy: 0.1378 - val_loss: 2.2377 - val_accuracy: 0.1270\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.2206 - accuracy: 0.1395 - val_loss: 2.1773 - val_accuracy: 0.1687\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2167 - accuracy: 0.1404 - val_loss: 2.1629 - val_accuracy: 0.1784\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.2219 - accuracy: 0.1379 - val_loss: 2.1425 - val_accuracy: 0.1804\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 11.8383 - accuracy: 0.0982 - val_loss: 4.2552 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2597 - accuracy: 0.0967 - val_loss: 4.2638 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2643 - accuracy: 0.0975 - val_loss: 4.2650 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2653 - accuracy: 0.0975 - val_loss: 4.2664 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.2655 - accuracy: 0.0974 - val_loss: 4.2659 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2655 - accuracy: 0.0982 - val_loss: 4.2670 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.2654 - accuracy: 0.0985 - val_loss: 4.2670 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 4.2654 - accuracy: 0.0969 - val_loss: 4.2665 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.2654 - accuracy: 0.0970 - val_loss: 4.2628 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2654 - accuracy: 0.0985 - val_loss: 4.2634 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.2653 - accuracy: 0.0983 - val_loss: 4.2620 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.2653 - accuracy: 0.0981 - val_loss: 4.2676 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.2653 - accuracy: 0.1000 - val_loss: 4.2670 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.2653 - accuracy: 0.0981 - val_loss: 4.2652 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 4.2652 - accuracy: 0.0966 - val_loss: 4.2650 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2652 - accuracy: 0.0978 - val_loss: 4.2652 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.2652 - accuracy: 0.0986 - val_loss: 4.2662 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 4.2652 - accuracy: 0.0969 - val_loss: 4.2659 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 4.2651 - accuracy: 0.0991 - val_loss: 4.2640 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 4.2652 - accuracy: 0.0991 - val_loss: 4.2645 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 3.4286 - accuracy: 0.1006 - val_loss: 2.5459 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.4520 - accuracy: 0.0991 - val_loss: 2.3822 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3482 - accuracy: 0.0979 - val_loss: 2.3250 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.3198 - accuracy: 0.0980 - val_loss: 2.3192 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3203 - accuracy: 0.0979 - val_loss: 2.3210 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3217 - accuracy: 0.1005 - val_loss: 2.3221 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3224 - accuracy: 0.0976 - val_loss: 2.3224 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3227 - accuracy: 0.0960 - val_loss: 2.3225 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0962 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0973 - val_loss: 2.3227 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0993 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0982 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0972 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0970 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0966 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0985 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0974 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0987 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3228 - accuracy: 0.0975 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3227 - accuracy: 0.0970 - val_loss: 2.3226 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3439 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3036 - accuracy: 0.0993 - val_loss: 2.3031 - val_accuracy: 0.1001\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3033 - accuracy: 0.0980 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3034 - accuracy: 0.0998 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3033 - accuracy: 0.0997 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3036 - accuracy: 0.0987 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3030 - accuracy: 0.0992 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3030 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3031 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3030 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 3.7167 - accuracy: 0.0996 - val_loss: 2.3316 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3084 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 2.4333 - accuracy: 0.0990 - val_loss: 2.3675 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3490 - accuracy: 0.0988 - val_loss: 2.3328 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3237 - accuracy: 0.1014 - val_loss: 2.3153 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3108 - accuracy: 0.0981 - val_loss: 2.3068 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3051 - accuracy: 0.0979 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3032 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 32, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3532 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3032 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3030 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3029 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3030 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3029 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 24.2021 - accuracy: 0.0979 - val_loss: 4.4400 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4369 - accuracy: 0.1001 - val_loss: 4.4400 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4372 - accuracy: 0.0990 - val_loss: 4.4394 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0973 - val_loss: 4.4383 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0978 - val_loss: 4.4335 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0975 - val_loss: 4.4371 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0990 - val_loss: 4.4492 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0980 - val_loss: 4.4415 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0994 - val_loss: 4.4411 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0985 - val_loss: 4.4444 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4375 - accuracy: 0.0998 - val_loss: 4.4426 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0983 - val_loss: 4.4412 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4375 - accuracy: 0.0963 - val_loss: 4.4360 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0972 - val_loss: 4.4432 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4374 - accuracy: 0.0994 - val_loss: 4.4273 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0981 - val_loss: 4.4364 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0993 - val_loss: 4.4405 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4372 - accuracy: 0.0973 - val_loss: 4.4377 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0976 - val_loss: 4.4282 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4373 - accuracy: 0.0983 - val_loss: 4.4318 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 3.3514 - accuracy: 0.2457 - val_loss: 2.4389 - val_accuracy: 0.3143\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3643 - accuracy: 0.3096 - val_loss: 2.2046 - val_accuracy: 0.3383\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1950 - accuracy: 0.3280 - val_loss: 2.0232 - val_accuracy: 0.3814\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0811 - accuracy: 0.3412 - val_loss: 1.9613 - val_accuracy: 0.3846\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0282 - accuracy: 0.3415 - val_loss: 1.9005 - val_accuracy: 0.3921\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9946 - accuracy: 0.3494 - val_loss: 1.8832 - val_accuracy: 0.4010\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9728 - accuracy: 0.3528 - val_loss: 1.8450 - val_accuracy: 0.4050\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9548 - accuracy: 0.3577 - val_loss: 1.8741 - val_accuracy: 0.3948\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9418 - accuracy: 0.3595 - val_loss: 1.8475 - val_accuracy: 0.4122\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9406 - accuracy: 0.3615 - val_loss: 1.7904 - val_accuracy: 0.4249\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9189 - accuracy: 0.3684 - val_loss: 1.8488 - val_accuracy: 0.3979\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9211 - accuracy: 0.3685 - val_loss: 1.8326 - val_accuracy: 0.4126\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9153 - accuracy: 0.3681 - val_loss: 1.8474 - val_accuracy: 0.3909\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9131 - accuracy: 0.3724 - val_loss: 1.8402 - val_accuracy: 0.4130\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8931 - accuracy: 0.3787 - val_loss: 1.8153 - val_accuracy: 0.4110\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8954 - accuracy: 0.3776 - val_loss: 1.8008 - val_accuracy: 0.4253\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8994 - accuracy: 0.3783 - val_loss: 1.7853 - val_accuracy: 0.4360\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9217 - accuracy: 0.3659 - val_loss: 1.8282 - val_accuracy: 0.4102\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9069 - accuracy: 0.3719 - val_loss: 1.7837 - val_accuracy: 0.4230\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8937 - accuracy: 0.3775 - val_loss: 1.8203 - val_accuracy: 0.4052\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0293 - accuracy: 0.2514 - val_loss: 1.8336 - val_accuracy: 0.3429\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8832 - accuracy: 0.3140 - val_loss: 1.7644 - val_accuracy: 0.3573\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8351 - accuracy: 0.3315 - val_loss: 1.7733 - val_accuracy: 0.3679\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7831 - accuracy: 0.3492 - val_loss: 1.6993 - val_accuracy: 0.3972\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7648 - accuracy: 0.3599 - val_loss: 1.6753 - val_accuracy: 0.4125\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7401 - accuracy: 0.3658 - val_loss: 1.6522 - val_accuracy: 0.4171\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7241 - accuracy: 0.3774 - val_loss: 1.6557 - val_accuracy: 0.4198\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7152 - accuracy: 0.3820 - val_loss: 1.6201 - val_accuracy: 0.4222\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6956 - accuracy: 0.3858 - val_loss: 1.6305 - val_accuracy: 0.4198\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6819 - accuracy: 0.3907 - val_loss: 1.5994 - val_accuracy: 0.4338\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6815 - accuracy: 0.3939 - val_loss: 1.5772 - val_accuracy: 0.4475\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6659 - accuracy: 0.4001 - val_loss: 1.5705 - val_accuracy: 0.4441\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6559 - accuracy: 0.4012 - val_loss: 1.5954 - val_accuracy: 0.4471\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6461 - accuracy: 0.4058 - val_loss: 1.5853 - val_accuracy: 0.4341\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6481 - accuracy: 0.4075 - val_loss: 1.5486 - val_accuracy: 0.4580\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6353 - accuracy: 0.4108 - val_loss: 1.5653 - val_accuracy: 0.4479\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6282 - accuracy: 0.4139 - val_loss: 1.5625 - val_accuracy: 0.4503\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6271 - accuracy: 0.4144 - val_loss: 1.5818 - val_accuracy: 0.4369\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6236 - accuracy: 0.4147 - val_loss: 1.5719 - val_accuracy: 0.4503\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6143 - accuracy: 0.4166 - val_loss: 1.5321 - val_accuracy: 0.4607\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 3.5732 - accuracy: 0.2268 - val_loss: 2.1016 - val_accuracy: 0.3122\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0977 - accuracy: 0.2817 - val_loss: 2.0218 - val_accuracy: 0.3157\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0531 - accuracy: 0.2911 - val_loss: 1.9746 - val_accuracy: 0.3128\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0396 - accuracy: 0.2909 - val_loss: 1.9663 - val_accuracy: 0.3223\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0361 - accuracy: 0.2845 - val_loss: 1.9666 - val_accuracy: 0.3271\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0225 - accuracy: 0.2923 - val_loss: 1.9548 - val_accuracy: 0.3089\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0299 - accuracy: 0.2839 - val_loss: 1.9428 - val_accuracy: 0.3240\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0166 - accuracy: 0.2908 - val_loss: 1.9349 - val_accuracy: 0.3292\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0355 - accuracy: 0.2827 - val_loss: 1.9269 - val_accuracy: 0.3286\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0220 - accuracy: 0.2870 - val_loss: 1.9460 - val_accuracy: 0.3318\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0166 - accuracy: 0.2884 - val_loss: 1.9548 - val_accuracy: 0.3164\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0187 - accuracy: 0.2828 - val_loss: 1.9275 - val_accuracy: 0.3255\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0050 - accuracy: 0.2890 - val_loss: 1.9159 - val_accuracy: 0.3416\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0121 - accuracy: 0.2845 - val_loss: 1.9509 - val_accuracy: 0.3241\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0125 - accuracy: 0.2871 - val_loss: 1.9193 - val_accuracy: 0.3385\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0139 - accuracy: 0.2851 - val_loss: 1.9507 - val_accuracy: 0.3215\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0376 - accuracy: 0.2634 - val_loss: 1.9715 - val_accuracy: 0.3066\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0244 - accuracy: 0.2738 - val_loss: 1.9455 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0140 - accuracy: 0.2817 - val_loss: 1.9217 - val_accuracy: 0.3237\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0083 - accuracy: 0.2863 - val_loss: 2.0026 - val_accuracy: 0.2689\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2.1334 - accuracy: 0.2499 - val_loss: 1.8991 - val_accuracy: 0.3444\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9566 - accuracy: 0.3061 - val_loss: 1.8305 - val_accuracy: 0.3629\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8854 - accuracy: 0.3281 - val_loss: 1.7497 - val_accuracy: 0.3933\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8372 - accuracy: 0.3472 - val_loss: 1.7587 - val_accuracy: 0.3809\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8123 - accuracy: 0.3556 - val_loss: 1.7297 - val_accuracy: 0.4012\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7820 - accuracy: 0.3631 - val_loss: 1.6819 - val_accuracy: 0.4161\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7766 - accuracy: 0.3697 - val_loss: 1.6797 - val_accuracy: 0.4180\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7564 - accuracy: 0.3755 - val_loss: 1.6643 - val_accuracy: 0.4311\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7422 - accuracy: 0.3824 - val_loss: 1.6676 - val_accuracy: 0.4179\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7358 - accuracy: 0.3823 - val_loss: 1.6413 - val_accuracy: 0.4335\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7280 - accuracy: 0.3874 - val_loss: 1.6486 - val_accuracy: 0.4362\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7239 - accuracy: 0.3900 - val_loss: 1.6312 - val_accuracy: 0.4366\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7129 - accuracy: 0.3927 - val_loss: 1.6581 - val_accuracy: 0.4289\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7055 - accuracy: 0.3965 - val_loss: 1.6204 - val_accuracy: 0.4345\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7033 - accuracy: 0.3972 - val_loss: 1.6326 - val_accuracy: 0.4395\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7034 - accuracy: 0.3987 - val_loss: 1.6105 - val_accuracy: 0.4480\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6965 - accuracy: 0.4003 - val_loss: 1.6203 - val_accuracy: 0.4483\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6890 - accuracy: 0.4066 - val_loss: 1.6109 - val_accuracy: 0.4483\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6862 - accuracy: 0.4048 - val_loss: 1.5981 - val_accuracy: 0.4463\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6846 - accuracy: 0.4090 - val_loss: 1.6115 - val_accuracy: 0.4520\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0354 - accuracy: 0.2519 - val_loss: 1.8404 - val_accuracy: 0.3360\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.8984 - accuracy: 0.3085 - val_loss: 1.7918 - val_accuracy: 0.3616\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8533 - accuracy: 0.3252 - val_loss: 1.7623 - val_accuracy: 0.3820\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8165 - accuracy: 0.3370 - val_loss: 1.7346 - val_accuracy: 0.3890\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7914 - accuracy: 0.3520 - val_loss: 1.6849 - val_accuracy: 0.4052\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7757 - accuracy: 0.3561 - val_loss: 1.6734 - val_accuracy: 0.4032\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7477 - accuracy: 0.3628 - val_loss: 1.6946 - val_accuracy: 0.3982\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7365 - accuracy: 0.3713 - val_loss: 1.6261 - val_accuracy: 0.4234\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7221 - accuracy: 0.3763 - val_loss: 1.6360 - val_accuracy: 0.4192\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7105 - accuracy: 0.3802 - val_loss: 1.6490 - val_accuracy: 0.4217\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.7002 - accuracy: 0.3848 - val_loss: 1.6298 - val_accuracy: 0.4272\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6868 - accuracy: 0.3919 - val_loss: 1.6314 - val_accuracy: 0.4175\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6776 - accuracy: 0.3958 - val_loss: 1.5856 - val_accuracy: 0.4419\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6702 - accuracy: 0.3973 - val_loss: 1.6190 - val_accuracy: 0.4321\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6562 - accuracy: 0.4005 - val_loss: 1.5955 - val_accuracy: 0.4440\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6526 - accuracy: 0.4033 - val_loss: 1.5830 - val_accuracy: 0.4393\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6475 - accuracy: 0.4082 - val_loss: 1.5797 - val_accuracy: 0.4456\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6334 - accuracy: 0.4124 - val_loss: 1.5725 - val_accuracy: 0.4364\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6330 - accuracy: 0.4113 - val_loss: 1.5802 - val_accuracy: 0.4521\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.6267 - accuracy: 0.4129 - val_loss: 1.5370 - val_accuracy: 0.4576\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 24.1527 - accuracy: 0.1010 - val_loss: 4.4340 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0966 - val_loss: 4.4369 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0990 - val_loss: 4.4381 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4326 - accuracy: 0.0977 - val_loss: 4.4338 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4325 - accuracy: 0.0977 - val_loss: 4.4304 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0986 - val_loss: 4.4285 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4325 - accuracy: 0.0977 - val_loss: 4.4425 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0984 - val_loss: 4.4355 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0974 - val_loss: 4.4370 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0969 - val_loss: 4.4371 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4325 - accuracy: 0.0990 - val_loss: 4.4329 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0983 - val_loss: 4.4328 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0980 - val_loss: 4.4263 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0995 - val_loss: 4.4373 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0970 - val_loss: 4.4227 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4324 - accuracy: 0.0990 - val_loss: 4.4321 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0989 - val_loss: 4.4335 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4323 - accuracy: 0.0980 - val_loss: 4.4296 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0973 - val_loss: 4.4232 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4323 - accuracy: 0.0970 - val_loss: 4.4275 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 3.2323 - accuracy: 0.2863 - val_loss: 2.3594 - val_accuracy: 0.3318\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.2575 - accuracy: 0.3463 - val_loss: 2.0890 - val_accuracy: 0.3963\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0767 - accuracy: 0.3675 - val_loss: 1.9729 - val_accuracy: 0.3903\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9778 - accuracy: 0.3811 - val_loss: 1.9280 - val_accuracy: 0.3825\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9242 - accuracy: 0.3869 - val_loss: 1.8580 - val_accuracy: 0.4076\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8838 - accuracy: 0.3962 - val_loss: 1.8277 - val_accuracy: 0.4176\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8579 - accuracy: 0.4013 - val_loss: 1.8088 - val_accuracy: 0.4134\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8444 - accuracy: 0.4037 - val_loss: 1.7629 - val_accuracy: 0.4379\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8300 - accuracy: 0.4112 - val_loss: 1.7852 - val_accuracy: 0.4333\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8162 - accuracy: 0.4113 - val_loss: 1.7624 - val_accuracy: 0.4318\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8168 - accuracy: 0.4141 - val_loss: 1.7597 - val_accuracy: 0.4369\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8096 - accuracy: 0.4177 - val_loss: 1.7510 - val_accuracy: 0.4416\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7882 - accuracy: 0.4259 - val_loss: 1.7156 - val_accuracy: 0.4513\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7954 - accuracy: 0.4217 - val_loss: 1.7111 - val_accuracy: 0.4638\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7822 - accuracy: 0.4280 - val_loss: 1.7446 - val_accuracy: 0.4438\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7740 - accuracy: 0.4318 - val_loss: 1.7168 - val_accuracy: 0.4574\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7776 - accuracy: 0.4288 - val_loss: 1.7499 - val_accuracy: 0.4453\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7718 - accuracy: 0.4338 - val_loss: 1.7028 - val_accuracy: 0.4607\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7695 - accuracy: 0.4301 - val_loss: 1.7029 - val_accuracy: 0.4512\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7578 - accuracy: 0.4376 - val_loss: 1.6891 - val_accuracy: 0.4639\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9580 - accuracy: 0.2829 - val_loss: 1.7839 - val_accuracy: 0.3589\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7745 - accuracy: 0.3586 - val_loss: 1.6583 - val_accuracy: 0.4063\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6973 - accuracy: 0.3930 - val_loss: 1.6105 - val_accuracy: 0.4251\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6456 - accuracy: 0.4078 - val_loss: 1.5778 - val_accuracy: 0.4455\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6064 - accuracy: 0.4244 - val_loss: 1.5122 - val_accuracy: 0.4624\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5761 - accuracy: 0.4338 - val_loss: 1.5094 - val_accuracy: 0.4590\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5535 - accuracy: 0.4423 - val_loss: 1.5081 - val_accuracy: 0.4596\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5280 - accuracy: 0.4508 - val_loss: 1.4829 - val_accuracy: 0.4698\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5060 - accuracy: 0.4609 - val_loss: 1.4867 - val_accuracy: 0.4701\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4888 - accuracy: 0.4659 - val_loss: 1.4701 - val_accuracy: 0.4716\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.4782 - accuracy: 0.4686 - val_loss: 1.4704 - val_accuracy: 0.4677\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4645 - accuracy: 0.4728 - val_loss: 1.4298 - val_accuracy: 0.4910\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.4524 - accuracy: 0.4800 - val_loss: 1.4464 - val_accuracy: 0.4852\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4386 - accuracy: 0.4840 - val_loss: 1.4418 - val_accuracy: 0.4878\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.4182 - accuracy: 0.4896 - val_loss: 1.4195 - val_accuracy: 0.4974\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.4143 - accuracy: 0.4928 - val_loss: 1.4296 - val_accuracy: 0.4895\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.4089 - accuracy: 0.4932 - val_loss: 1.4127 - val_accuracy: 0.4908\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.3886 - accuracy: 0.5041 - val_loss: 1.4148 - val_accuracy: 0.4984\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.3806 - accuracy: 0.5035 - val_loss: 1.4034 - val_accuracy: 0.5055\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.3719 - accuracy: 0.5091 - val_loss: 1.3795 - val_accuracy: 0.5122\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 3.5404 - accuracy: 0.2650 - val_loss: 2.1159 - val_accuracy: 0.3228\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0701 - accuracy: 0.3159 - val_loss: 1.9816 - val_accuracy: 0.3497\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9964 - accuracy: 0.3262 - val_loss: 1.9133 - val_accuracy: 0.3565\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9618 - accuracy: 0.3345 - val_loss: 1.8954 - val_accuracy: 0.3594\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9576 - accuracy: 0.3323 - val_loss: 1.9235 - val_accuracy: 0.3354\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9494 - accuracy: 0.3354 - val_loss: 1.8949 - val_accuracy: 0.3547\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9407 - accuracy: 0.3389 - val_loss: 1.8562 - val_accuracy: 0.3650\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9371 - accuracy: 0.3371 - val_loss: 1.8895 - val_accuracy: 0.3611\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9314 - accuracy: 0.3379 - val_loss: 1.8767 - val_accuracy: 0.3525\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9290 - accuracy: 0.3416 - val_loss: 1.8934 - val_accuracy: 0.3561\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9306 - accuracy: 0.3428 - val_loss: 1.8568 - val_accuracy: 0.3789\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9101 - accuracy: 0.3498 - val_loss: 1.8343 - val_accuracy: 0.3840\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9169 - accuracy: 0.3451 - val_loss: 1.8384 - val_accuracy: 0.3793\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9194 - accuracy: 0.3471 - val_loss: 1.8467 - val_accuracy: 0.3806\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9226 - accuracy: 0.3460 - val_loss: 1.8665 - val_accuracy: 0.3750\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.8947 - accuracy: 0.3547 - val_loss: 1.8754 - val_accuracy: 0.3543\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9057 - accuracy: 0.3488 - val_loss: 1.8530 - val_accuracy: 0.3695\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9073 - accuracy: 0.3488 - val_loss: 1.8586 - val_accuracy: 0.3771\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.9022 - accuracy: 0.3490 - val_loss: 1.8536 - val_accuracy: 0.3750\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8982 - accuracy: 0.3486 - val_loss: 1.8231 - val_accuracy: 0.3855\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0690 - accuracy: 0.2796 - val_loss: 1.8477 - val_accuracy: 0.3637\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.8462 - accuracy: 0.3608 - val_loss: 1.7537 - val_accuracy: 0.3926\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7593 - accuracy: 0.3867 - val_loss: 1.6763 - val_accuracy: 0.4244\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6995 - accuracy: 0.4054 - val_loss: 1.6051 - val_accuracy: 0.4438\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6506 - accuracy: 0.4240 - val_loss: 1.5637 - val_accuracy: 0.4609\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6268 - accuracy: 0.4305 - val_loss: 1.5578 - val_accuracy: 0.4582\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5920 - accuracy: 0.4422 - val_loss: 1.5338 - val_accuracy: 0.4705\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5876 - accuracy: 0.4470 - val_loss: 1.5351 - val_accuracy: 0.4686\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5710 - accuracy: 0.4532 - val_loss: 1.5398 - val_accuracy: 0.4648\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5463 - accuracy: 0.4592 - val_loss: 1.5033 - val_accuracy: 0.4854\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5376 - accuracy: 0.4648 - val_loss: 1.4912 - val_accuracy: 0.4856\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5186 - accuracy: 0.4708 - val_loss: 1.4952 - val_accuracy: 0.4843\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5166 - accuracy: 0.4742 - val_loss: 1.4956 - val_accuracy: 0.4852\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5038 - accuracy: 0.4796 - val_loss: 1.4709 - val_accuracy: 0.4959\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4929 - accuracy: 0.4825 - val_loss: 1.4660 - val_accuracy: 0.4923\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4863 - accuracy: 0.4888 - val_loss: 1.4448 - val_accuracy: 0.5073\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4841 - accuracy: 0.4873 - val_loss: 1.4664 - val_accuracy: 0.4959\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4766 - accuracy: 0.4920 - val_loss: 1.4647 - val_accuracy: 0.4989\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4732 - accuracy: 0.4930 - val_loss: 1.4508 - val_accuracy: 0.5071\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4621 - accuracy: 0.4973 - val_loss: 1.4861 - val_accuracy: 0.4909\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.9424 - accuracy: 0.2917 - val_loss: 1.7763 - val_accuracy: 0.3619\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7685 - accuracy: 0.3630 - val_loss: 1.6881 - val_accuracy: 0.3930\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.7021 - accuracy: 0.3909 - val_loss: 1.6168 - val_accuracy: 0.4252\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6565 - accuracy: 0.4061 - val_loss: 1.5603 - val_accuracy: 0.4450\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.6103 - accuracy: 0.4228 - val_loss: 1.5355 - val_accuracy: 0.4496\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5851 - accuracy: 0.4300 - val_loss: 1.5108 - val_accuracy: 0.4619\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5613 - accuracy: 0.4387 - val_loss: 1.5119 - val_accuracy: 0.4630\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5417 - accuracy: 0.4452 - val_loss: 1.4726 - val_accuracy: 0.4755\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5217 - accuracy: 0.4526 - val_loss: 1.4896 - val_accuracy: 0.4630\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.5034 - accuracy: 0.4600 - val_loss: 1.4966 - val_accuracy: 0.4579\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4935 - accuracy: 0.4634 - val_loss: 1.4544 - val_accuracy: 0.4834\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4760 - accuracy: 0.4704 - val_loss: 1.4570 - val_accuracy: 0.4799\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4672 - accuracy: 0.4725 - val_loss: 1.4861 - val_accuracy: 0.4697\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4503 - accuracy: 0.4777 - val_loss: 1.4359 - val_accuracy: 0.4875\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4428 - accuracy: 0.4808 - val_loss: 1.4458 - val_accuracy: 0.4829\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4394 - accuracy: 0.4818 - val_loss: 1.4232 - val_accuracy: 0.4928\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4203 - accuracy: 0.4886 - val_loss: 1.4038 - val_accuracy: 0.4974\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4162 - accuracy: 0.4916 - val_loss: 1.4310 - val_accuracy: 0.4909\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.4110 - accuracy: 0.4910 - val_loss: 1.4364 - val_accuracy: 0.4888\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 1.3981 - accuracy: 0.4981 - val_loss: 1.4123 - val_accuracy: 0.4940\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 24.6999 - accuracy: 0.0983 - val_loss: 4.4500 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4492 - accuracy: 0.0985 - val_loss: 4.4510 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4503 - accuracy: 0.0963 - val_loss: 4.4524 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4508 - accuracy: 0.0980 - val_loss: 4.4536 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4510 - accuracy: 0.0969 - val_loss: 4.4513 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4510 - accuracy: 0.0985 - val_loss: 4.4536 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4512 - accuracy: 0.0978 - val_loss: 4.4639 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4512 - accuracy: 0.0987 - val_loss: 4.4532 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4511 - accuracy: 0.0991 - val_loss: 4.4555 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4511 - accuracy: 0.0968 - val_loss: 4.4574 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4513 - accuracy: 0.0965 - val_loss: 4.4577 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4511 - accuracy: 0.0978 - val_loss: 4.4534 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4512 - accuracy: 0.0974 - val_loss: 4.4511 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4511 - accuracy: 0.0971 - val_loss: 4.4541 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4512 - accuracy: 0.0975 - val_loss: 4.4410 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4511 - accuracy: 0.0973 - val_loss: 4.4506 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4511 - accuracy: 0.0988 - val_loss: 4.4526 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4510 - accuracy: 0.0976 - val_loss: 4.4497 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4510 - accuracy: 0.0983 - val_loss: 4.4442 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4511 - accuracy: 0.0972 - val_loss: 4.4451 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 3.7517 - accuracy: 0.1565 - val_loss: 2.6201 - val_accuracy: 0.2359\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.5488 - accuracy: 0.1926 - val_loss: 2.4111 - val_accuracy: 0.2344\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3873 - accuracy: 0.2084 - val_loss: 2.2804 - val_accuracy: 0.2541\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.2649 - accuracy: 0.2195 - val_loss: 2.1731 - val_accuracy: 0.2341\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1855 - accuracy: 0.2264 - val_loss: 2.1617 - val_accuracy: 0.2473\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1453 - accuracy: 0.2287 - val_loss: 2.0939 - val_accuracy: 0.2181\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1253 - accuracy: 0.2251 - val_loss: 2.1040 - val_accuracy: 0.2563\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1138 - accuracy: 0.2318 - val_loss: 2.1016 - val_accuracy: 0.2779\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1135 - accuracy: 0.2324 - val_loss: 2.0994 - val_accuracy: 0.2782\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1057 - accuracy: 0.2322 - val_loss: 2.1140 - val_accuracy: 0.2362\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1045 - accuracy: 0.2375 - val_loss: 2.0838 - val_accuracy: 0.2522\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1044 - accuracy: 0.2377 - val_loss: 2.1468 - val_accuracy: 0.2407\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1022 - accuracy: 0.2349 - val_loss: 2.0847 - val_accuracy: 0.2566\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1028 - accuracy: 0.2416 - val_loss: 2.0965 - val_accuracy: 0.2470\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1058 - accuracy: 0.2362 - val_loss: 2.1154 - val_accuracy: 0.2521\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1068 - accuracy: 0.2356 - val_loss: 2.1603 - val_accuracy: 0.2238\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1020 - accuracy: 0.2382 - val_loss: 2.1562 - val_accuracy: 0.2298\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0992 - accuracy: 0.2406 - val_loss: 2.1243 - val_accuracy: 0.2624\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0964 - accuracy: 0.2437 - val_loss: 2.1187 - val_accuracy: 0.2405\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0970 - accuracy: 0.2437 - val_loss: 2.0943 - val_accuracy: 0.2610\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2333 - accuracy: 0.1526 - val_loss: 2.0866 - val_accuracy: 0.2225\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1318 - accuracy: 0.1856 - val_loss: 2.0877 - val_accuracy: 0.1962\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1093 - accuracy: 0.1884 - val_loss: 2.0540 - val_accuracy: 0.2405\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0967 - accuracy: 0.1933 - val_loss: 2.0697 - val_accuracy: 0.2485\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0956 - accuracy: 0.1989 - val_loss: 2.0798 - val_accuracy: 0.2429\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0930 - accuracy: 0.1972 - val_loss: 2.0479 - val_accuracy: 0.2487\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0868 - accuracy: 0.1994 - val_loss: 2.0792 - val_accuracy: 0.2385\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0847 - accuracy: 0.2043 - val_loss: 2.0450 - val_accuracy: 0.2506\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0799 - accuracy: 0.2010 - val_loss: 2.0471 - val_accuracy: 0.2209\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0758 - accuracy: 0.2045 - val_loss: 2.0437 - val_accuracy: 0.2361\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0753 - accuracy: 0.2081 - val_loss: 2.1278 - val_accuracy: 0.2201\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0774 - accuracy: 0.2060 - val_loss: 2.0643 - val_accuracy: 0.2453\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0699 - accuracy: 0.2073 - val_loss: 2.0634 - val_accuracy: 0.2390\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0720 - accuracy: 0.2059 - val_loss: 2.0236 - val_accuracy: 0.2459\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0578 - accuracy: 0.2113 - val_loss: 2.1015 - val_accuracy: 0.2171\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0519 - accuracy: 0.2160 - val_loss: 2.0723 - val_accuracy: 0.2385\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0498 - accuracy: 0.2151 - val_loss: 2.0365 - val_accuracy: 0.2424\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0429 - accuracy: 0.2165 - val_loss: 2.0298 - val_accuracy: 0.2463\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0344 - accuracy: 0.2192 - val_loss: 2.0710 - val_accuracy: 0.2230\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0334 - accuracy: 0.2217 - val_loss: 2.0289 - val_accuracy: 0.2565\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.0908 - accuracy: 0.1575 - val_loss: 2.2166 - val_accuracy: 0.2228\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2134 - accuracy: 0.1921 - val_loss: 2.1493 - val_accuracy: 0.2474\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1753 - accuracy: 0.1951 - val_loss: 2.1227 - val_accuracy: 0.2339\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1728 - accuracy: 0.1899 - val_loss: 2.0837 - val_accuracy: 0.2496\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1595 - accuracy: 0.1936 - val_loss: 2.1233 - val_accuracy: 0.2188\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1704 - accuracy: 0.1854 - val_loss: 2.0962 - val_accuracy: 0.2252\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1667 - accuracy: 0.1858 - val_loss: 2.1452 - val_accuracy: 0.2012\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1779 - accuracy: 0.1791 - val_loss: 2.1143 - val_accuracy: 0.1957\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1681 - accuracy: 0.1789 - val_loss: 2.1476 - val_accuracy: 0.2206\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1619 - accuracy: 0.1836 - val_loss: 2.1282 - val_accuracy: 0.2011\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1636 - accuracy: 0.1817 - val_loss: 2.1296 - val_accuracy: 0.2022\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1611 - accuracy: 0.1833 - val_loss: 2.1416 - val_accuracy: 0.1947\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1662 - accuracy: 0.1836 - val_loss: 2.1375 - val_accuracy: 0.2249\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1670 - accuracy: 0.1816 - val_loss: 2.1034 - val_accuracy: 0.2408\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1564 - accuracy: 0.1827 - val_loss: 2.1707 - val_accuracy: 0.2149\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1694 - accuracy: 0.1819 - val_loss: 2.1214 - val_accuracy: 0.2262\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1630 - accuracy: 0.1825 - val_loss: 2.0983 - val_accuracy: 0.2243\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1569 - accuracy: 0.1857 - val_loss: 2.1312 - val_accuracy: 0.1992\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1596 - accuracy: 0.1830 - val_loss: 2.1291 - val_accuracy: 0.2289\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.1561 - accuracy: 0.1840 - val_loss: 2.1032 - val_accuracy: 0.1990\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3533 - accuracy: 0.1424 - val_loss: 2.2091 - val_accuracy: 0.2112\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1935 - accuracy: 0.1819 - val_loss: 2.1268 - val_accuracy: 0.2390\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1378 - accuracy: 0.2013 - val_loss: 2.0577 - val_accuracy: 0.2626\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1029 - accuracy: 0.2090 - val_loss: 2.0392 - val_accuracy: 0.2647\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0820 - accuracy: 0.2142 - val_loss: 2.0209 - val_accuracy: 0.2739\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0644 - accuracy: 0.2162 - val_loss: 2.0309 - val_accuracy: 0.2296\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0496 - accuracy: 0.2208 - val_loss: 2.0167 - val_accuracy: 0.2597\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2.0478 - accuracy: 0.2197 - val_loss: 2.0146 - val_accuracy: 0.2624\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0382 - accuracy: 0.2208 - val_loss: 2.0048 - val_accuracy: 0.2659\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0291 - accuracy: 0.2256 - val_loss: 2.0089 - val_accuracy: 0.2525\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0224 - accuracy: 0.2269 - val_loss: 2.0141 - val_accuracy: 0.2504\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0226 - accuracy: 0.2299 - val_loss: 2.0267 - val_accuracy: 0.2631\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0201 - accuracy: 0.2310 - val_loss: 2.0116 - val_accuracy: 0.2608\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0191 - accuracy: 0.2295 - val_loss: 2.0682 - val_accuracy: 0.2331\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0158 - accuracy: 0.2335 - val_loss: 1.9968 - val_accuracy: 0.2578\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0161 - accuracy: 0.2311 - val_loss: 2.0508 - val_accuracy: 0.2557\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0113 - accuracy: 0.2335 - val_loss: 2.0308 - val_accuracy: 0.2491\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0126 - accuracy: 0.2340 - val_loss: 2.0220 - val_accuracy: 0.2363\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0068 - accuracy: 0.2384 - val_loss: 2.0600 - val_accuracy: 0.2479\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0084 - accuracy: 0.2360 - val_loss: 2.0134 - val_accuracy: 0.2589\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.2265 - accuracy: 0.1421 - val_loss: 2.0670 - val_accuracy: 0.2159\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.1249 - accuracy: 0.1708 - val_loss: 2.0549 - val_accuracy: 0.2365\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0968 - accuracy: 0.1914 - val_loss: 2.0273 - val_accuracy: 0.2613\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0847 - accuracy: 0.1977 - val_loss: 2.0015 - val_accuracy: 0.2580\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0704 - accuracy: 0.2038 - val_loss: 1.9940 - val_accuracy: 0.2781\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0745 - accuracy: 0.2061 - val_loss: 1.9786 - val_accuracy: 0.2573\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0625 - accuracy: 0.2118 - val_loss: 2.0064 - val_accuracy: 0.2548\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0505 - accuracy: 0.2176 - val_loss: 2.0206 - val_accuracy: 0.2354\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0499 - accuracy: 0.2174 - val_loss: 2.0147 - val_accuracy: 0.2729\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0416 - accuracy: 0.2225 - val_loss: 1.9780 - val_accuracy: 0.2371\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0407 - accuracy: 0.2235 - val_loss: 1.9908 - val_accuracy: 0.2445\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0344 - accuracy: 0.2272 - val_loss: 2.0207 - val_accuracy: 0.2451\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0341 - accuracy: 0.2250 - val_loss: 2.0224 - val_accuracy: 0.2451\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0302 - accuracy: 0.2303 - val_loss: 1.9965 - val_accuracy: 0.2713\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0303 - accuracy: 0.2299 - val_loss: 2.0130 - val_accuracy: 0.2469\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0270 - accuracy: 0.2311 - val_loss: 2.0474 - val_accuracy: 0.2340\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0275 - accuracy: 0.2319 - val_loss: 2.0618 - val_accuracy: 0.2318\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0240 - accuracy: 0.2294 - val_loss: 2.0532 - val_accuracy: 0.2406\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.0259 - accuracy: 0.2306 - val_loss: 1.9940 - val_accuracy: 0.2493\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.0239 - accuracy: 0.2333 - val_loss: 2.0224 - val_accuracy: 0.2328\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 27.4516 - accuracy: 0.0983 - val_loss: 4.4152 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4189 - accuracy: 0.0995 - val_loss: 4.4226 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4239 - accuracy: 0.0985 - val_loss: 4.4264 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4258 - accuracy: 0.0977 - val_loss: 4.4255 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4268 - accuracy: 0.0958 - val_loss: 4.4260 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4274 - accuracy: 0.0978 - val_loss: 4.4200 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4277 - accuracy: 0.0972 - val_loss: 4.4269 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4279 - accuracy: 0.0967 - val_loss: 4.4263 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4280 - accuracy: 0.0971 - val_loss: 4.4268 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4280 - accuracy: 0.0993 - val_loss: 4.4221 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.4282 - accuracy: 0.1001 - val_loss: 4.4262 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4282 - accuracy: 0.0989 - val_loss: 4.4240 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4282 - accuracy: 0.0981 - val_loss: 4.4224 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4281 - accuracy: 0.0982 - val_loss: 4.4288 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4283 - accuracy: 0.0995 - val_loss: 4.4237 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4281 - accuracy: 0.1000 - val_loss: 4.4240 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4281 - accuracy: 0.0997 - val_loss: 4.4266 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4282 - accuracy: 0.0983 - val_loss: 4.4287 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4282 - accuracy: 0.0981 - val_loss: 4.4259 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 4.4280 - accuracy: 0.0974 - val_loss: 4.4310 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 4.3722 - accuracy: 0.1096 - val_loss: 3.1749 - val_accuracy: 0.1632\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.8032 - accuracy: 0.1311 - val_loss: 2.5623 - val_accuracy: 0.1733\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.5010 - accuracy: 0.1459 - val_loss: 2.4377 - val_accuracy: 0.1516\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3569 - accuracy: 0.1567 - val_loss: 2.3404 - val_accuracy: 0.1425\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2863 - accuracy: 0.1601 - val_loss: 2.2990 - val_accuracy: 0.1523\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2648 - accuracy: 0.1626 - val_loss: 2.2841 - val_accuracy: 0.1445\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2400 - accuracy: 0.1656 - val_loss: 2.3034 - val_accuracy: 0.1395\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2283 - accuracy: 0.1689 - val_loss: 2.2888 - val_accuracy: 0.1570\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2249 - accuracy: 0.1686 - val_loss: 2.2849 - val_accuracy: 0.1404\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2211 - accuracy: 0.1706 - val_loss: 2.3130 - val_accuracy: 0.1277\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2210 - accuracy: 0.1694 - val_loss: 2.2888 - val_accuracy: 0.1391\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2232 - accuracy: 0.1672 - val_loss: 2.2548 - val_accuracy: 0.1602\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2185 - accuracy: 0.1704 - val_loss: 2.2259 - val_accuracy: 0.1663\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2192 - accuracy: 0.1704 - val_loss: 2.2751 - val_accuracy: 0.1434\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2212 - accuracy: 0.1702 - val_loss: 2.2714 - val_accuracy: 0.1489\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2186 - accuracy: 0.1698 - val_loss: 2.2829 - val_accuracy: 0.1446\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2128 - accuracy: 0.1707 - val_loss: 2.2682 - val_accuracy: 0.1663\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2187 - accuracy: 0.1689 - val_loss: 2.2934 - val_accuracy: 0.1290\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2142 - accuracy: 0.1708 - val_loss: 2.2796 - val_accuracy: 0.1448\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2118 - accuracy: 0.1733 - val_loss: 2.2648 - val_accuracy: 0.1597\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3499 - accuracy: 0.0986 - val_loss: 2.3042 - val_accuracy: 0.1008\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3033 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3032 - accuracy: 0.0954 - val_loss: 2.3030 - val_accuracy: 0.0995\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3033 - accuracy: 0.0992 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3032 - accuracy: 0.0981 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3032 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.0999\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0977 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0971 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0980 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3030 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0973 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0991 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3032 - accuracy: 0.0956 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3030 - accuracy: 0.0988 - val_loss: 2.3029 - val_accuracy: 0.1001\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0962 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.0987 - val_loss: 2.3029 - val_accuracy: 0.1001\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3030 - accuracy: 0.0974 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3030 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 5.1568 - accuracy: 0.1142 - val_loss: 2.4586 - val_accuracy: 0.1865\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3431 - accuracy: 0.1407 - val_loss: 2.2365 - val_accuracy: 0.1828\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2693 - accuracy: 0.1425 - val_loss: 2.2010 - val_accuracy: 0.1769\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2515 - accuracy: 0.1435 - val_loss: 2.2136 - val_accuracy: 0.1734\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2458 - accuracy: 0.1444 - val_loss: 2.2330 - val_accuracy: 0.1688\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2447 - accuracy: 0.1470 - val_loss: 2.2353 - val_accuracy: 0.1564\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2377 - accuracy: 0.1484 - val_loss: 2.2022 - val_accuracy: 0.1729\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2395 - accuracy: 0.1474 - val_loss: 2.2072 - val_accuracy: 0.1737\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2437 - accuracy: 0.1478 - val_loss: 2.2148 - val_accuracy: 0.1737\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2390 - accuracy: 0.1460 - val_loss: 2.2029 - val_accuracy: 0.1756\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2446 - accuracy: 0.1442 - val_loss: 2.2080 - val_accuracy: 0.1685\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2382 - accuracy: 0.1491 - val_loss: 2.2169 - val_accuracy: 0.1640\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2494 - accuracy: 0.1413 - val_loss: 2.2213 - val_accuracy: 0.1623\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2558 - accuracy: 0.1388 - val_loss: 2.2112 - val_accuracy: 0.1880\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2499 - accuracy: 0.1402 - val_loss: 2.2651 - val_accuracy: 0.1379\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2553 - accuracy: 0.1388 - val_loss: 2.2661 - val_accuracy: 0.1369\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2542 - accuracy: 0.1376 - val_loss: 2.2229 - val_accuracy: 0.1713\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2537 - accuracy: 0.1391 - val_loss: 2.2220 - val_accuracy: 0.1675\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2532 - accuracy: 0.1379 - val_loss: 2.2305 - val_accuracy: 0.1626\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.2539 - accuracy: 0.1361 - val_loss: 2.2677 - val_accuracy: 0.1349\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.4737 - accuracy: 0.0988 - val_loss: 2.4065 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3949 - accuracy: 0.0989 - val_loss: 2.3834 - val_accuracy: 0.0999\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3737 - accuracy: 0.0973 - val_loss: 2.3642 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3564 - accuracy: 0.0990 - val_loss: 2.3487 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3426 - accuracy: 0.1004 - val_loss: 2.3365 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3317 - accuracy: 0.0984 - val_loss: 2.3271 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3233 - accuracy: 0.0996 - val_loss: 2.3196 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3169 - accuracy: 0.0981 - val_loss: 2.3141 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3122 - accuracy: 0.0985 - val_loss: 2.3102 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3089 - accuracy: 0.0978 - val_loss: 2.3076 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3067 - accuracy: 0.0996 - val_loss: 2.3057 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3052 - accuracy: 0.0973 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3042 - accuracy: 0.0974 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3036 - accuracy: 0.0985 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3032 - accuracy: 0.0975 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3030 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 128, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3574 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3028 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 43.8568 - accuracy: 0.1062 - val_loss: 4.4448 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4361 - accuracy: 0.1009 - val_loss: 4.4395 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4362 - accuracy: 0.0995 - val_loss: 4.4396 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4362 - accuracy: 0.0985 - val_loss: 4.4330 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4368 - accuracy: 0.0995 - val_loss: 4.4334 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4359 - accuracy: 0.0973 - val_loss: 4.4410 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4367 - accuracy: 0.0972 - val_loss: 4.4528 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4362 - accuracy: 0.0972 - val_loss: 4.4397 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4364 - accuracy: 0.0976 - val_loss: 4.4410 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4363 - accuracy: 0.0986 - val_loss: 4.4404 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4366 - accuracy: 0.0951 - val_loss: 4.4356 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4360 - accuracy: 0.0982 - val_loss: 4.4471 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4367 - accuracy: 0.0993 - val_loss: 4.4346 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4364 - accuracy: 0.0969 - val_loss: 4.4350 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4361 - accuracy: 0.0980 - val_loss: 4.4377 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4365 - accuracy: 0.0999 - val_loss: 4.4467 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4362 - accuracy: 0.0989 - val_loss: 4.4392 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4363 - accuracy: 0.0973 - val_loss: 4.4476 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 4.4362 - accuracy: 0.0971 - val_loss: 4.4304 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4366 - accuracy: 0.0984 - val_loss: 4.4434 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 3.7534 - accuracy: 0.2361 - val_loss: 2.6444 - val_accuracy: 0.2762\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.4327 - accuracy: 0.3122 - val_loss: 2.2386 - val_accuracy: 0.3538\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 2.2486 - accuracy: 0.3370 - val_loss: 2.1381 - val_accuracy: 0.3606\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 2.1501 - accuracy: 0.3467 - val_loss: 2.0971 - val_accuracy: 0.3662\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 2.0732 - accuracy: 0.3540 - val_loss: 1.9279 - val_accuracy: 0.4066\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 2.0168 - accuracy: 0.3588 - val_loss: 1.9389 - val_accuracy: 0.3852\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.9734 - accuracy: 0.3660 - val_loss: 1.8775 - val_accuracy: 0.4103\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.9416 - accuracy: 0.3719 - val_loss: 1.8233 - val_accuracy: 0.4215\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.9251 - accuracy: 0.3709 - val_loss: 1.8645 - val_accuracy: 0.4080\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.9249 - accuracy: 0.3709 - val_loss: 1.7879 - val_accuracy: 0.4316\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8836 - accuracy: 0.3842 - val_loss: 1.7965 - val_accuracy: 0.4182\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8942 - accuracy: 0.3782 - val_loss: 1.7698 - val_accuracy: 0.4396\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8938 - accuracy: 0.3760 - val_loss: 1.7813 - val_accuracy: 0.4336\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8674 - accuracy: 0.3886 - val_loss: 1.7541 - val_accuracy: 0.4383\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8783 - accuracy: 0.3830 - val_loss: 1.7584 - val_accuracy: 0.4397\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8753 - accuracy: 0.3850 - val_loss: 1.7896 - val_accuracy: 0.4311\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8743 - accuracy: 0.3851 - val_loss: 1.7913 - val_accuracy: 0.4202\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8613 - accuracy: 0.3906 - val_loss: 1.7574 - val_accuracy: 0.4320\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8605 - accuracy: 0.3902 - val_loss: 1.7576 - val_accuracy: 0.4380\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.8480 - accuracy: 0.3933 - val_loss: 1.7565 - val_accuracy: 0.4428\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.0597 - accuracy: 0.2406 - val_loss: 1.8336 - val_accuracy: 0.3488\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8729 - accuracy: 0.3201 - val_loss: 1.7333 - val_accuracy: 0.3685\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8180 - accuracy: 0.3420 - val_loss: 1.7010 - val_accuracy: 0.3923\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7775 - accuracy: 0.3601 - val_loss: 1.6643 - val_accuracy: 0.4146\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7513 - accuracy: 0.3699 - val_loss: 1.6749 - val_accuracy: 0.4152\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7127 - accuracy: 0.3834 - val_loss: 1.6001 - val_accuracy: 0.4308\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7029 - accuracy: 0.3864 - val_loss: 1.6100 - val_accuracy: 0.4349\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6920 - accuracy: 0.3934 - val_loss: 1.6188 - val_accuracy: 0.4276\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6693 - accuracy: 0.3996 - val_loss: 1.5936 - val_accuracy: 0.4302\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6686 - accuracy: 0.3983 - val_loss: 1.5960 - val_accuracy: 0.4397\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6682 - accuracy: 0.3990 - val_loss: 1.5829 - val_accuracy: 0.4340\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6411 - accuracy: 0.4100 - val_loss: 1.5528 - val_accuracy: 0.4484\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6347 - accuracy: 0.4126 - val_loss: 1.5693 - val_accuracy: 0.4429\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6208 - accuracy: 0.4179 - val_loss: 1.5615 - val_accuracy: 0.4570\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 1.6240 - accuracy: 0.4135 - val_loss: 1.5357 - val_accuracy: 0.4549\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6137 - accuracy: 0.4195 - val_loss: 1.5752 - val_accuracy: 0.4329\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 14ms/step - loss: 1.5995 - accuracy: 0.4243 - val_loss: 1.5249 - val_accuracy: 0.4581\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5921 - accuracy: 0.4271 - val_loss: 1.5348 - val_accuracy: 0.4588\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5857 - accuracy: 0.4310 - val_loss: 1.5143 - val_accuracy: 0.4709\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 14ms/step - loss: 1.5853 - accuracy: 0.4298 - val_loss: 1.5216 - val_accuracy: 0.4612\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 18ms/step - loss: 4.7226 - accuracy: 0.2249 - val_loss: 2.3094 - val_accuracy: 0.3017\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1782 - accuracy: 0.2909 - val_loss: 2.0432 - val_accuracy: 0.3120\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0600 - accuracy: 0.3029 - val_loss: 1.9880 - val_accuracy: 0.3150\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0179 - accuracy: 0.3109 - val_loss: 1.9471 - val_accuracy: 0.3353\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0103 - accuracy: 0.3113 - val_loss: 2.0051 - val_accuracy: 0.3168\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9911 - accuracy: 0.3160 - val_loss: 1.9566 - val_accuracy: 0.3392\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9768 - accuracy: 0.3188 - val_loss: 1.9155 - val_accuracy: 0.3540\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9871 - accuracy: 0.3147 - val_loss: 1.9142 - val_accuracy: 0.3452\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9915 - accuracy: 0.3143 - val_loss: 1.9196 - val_accuracy: 0.3420\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9654 - accuracy: 0.3199 - val_loss: 1.8925 - val_accuracy: 0.3624\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9749 - accuracy: 0.3186 - val_loss: 1.9326 - val_accuracy: 0.3259\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9794 - accuracy: 0.3134 - val_loss: 1.9366 - val_accuracy: 0.3341\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9692 - accuracy: 0.3165 - val_loss: 1.9078 - val_accuracy: 0.3500\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9701 - accuracy: 0.3169 - val_loss: 1.8963 - val_accuracy: 0.3495\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9595 - accuracy: 0.3214 - val_loss: 1.9087 - val_accuracy: 0.3467\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9670 - accuracy: 0.3195 - val_loss: 1.8855 - val_accuracy: 0.3504\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9684 - accuracy: 0.3174 - val_loss: 1.8713 - val_accuracy: 0.3605\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9605 - accuracy: 0.3209 - val_loss: 1.8783 - val_accuracy: 0.3609\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9492 - accuracy: 0.3220 - val_loss: 1.8582 - val_accuracy: 0.3663\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9601 - accuracy: 0.3187 - val_loss: 1.9003 - val_accuracy: 0.3318\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.1617 - accuracy: 0.2429 - val_loss: 1.9324 - val_accuracy: 0.3440\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9566 - accuracy: 0.3178 - val_loss: 1.8412 - val_accuracy: 0.3712\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8874 - accuracy: 0.3387 - val_loss: 1.7708 - val_accuracy: 0.3954\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8482 - accuracy: 0.3496 - val_loss: 1.7522 - val_accuracy: 0.3982\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7945 - accuracy: 0.3648 - val_loss: 1.6808 - val_accuracy: 0.4140\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.7663 - accuracy: 0.3765 - val_loss: 1.6663 - val_accuracy: 0.4189\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7525 - accuracy: 0.3801 - val_loss: 1.6492 - val_accuracy: 0.4298\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7268 - accuracy: 0.3910 - val_loss: 1.6410 - val_accuracy: 0.4339\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7112 - accuracy: 0.3979 - val_loss: 1.6216 - val_accuracy: 0.4397\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7085 - accuracy: 0.3942 - val_loss: 1.6355 - val_accuracy: 0.4283\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6943 - accuracy: 0.4002 - val_loss: 1.6122 - val_accuracy: 0.4454\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6772 - accuracy: 0.4078 - val_loss: 1.6047 - val_accuracy: 0.4504\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6666 - accuracy: 0.4103 - val_loss: 1.6030 - val_accuracy: 0.4478\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6671 - accuracy: 0.4096 - val_loss: 1.5993 - val_accuracy: 0.4511\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6600 - accuracy: 0.4133 - val_loss: 1.5650 - val_accuracy: 0.4640\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6485 - accuracy: 0.4199 - val_loss: 1.5858 - val_accuracy: 0.4538\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6418 - accuracy: 0.4227 - val_loss: 1.5628 - val_accuracy: 0.4552\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6323 - accuracy: 0.4271 - val_loss: 1.5870 - val_accuracy: 0.4524\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6349 - accuracy: 0.4206 - val_loss: 1.5683 - val_accuracy: 0.4536\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6281 - accuracy: 0.4270 - val_loss: 1.5914 - val_accuracy: 0.4517\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.25, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.0745 - accuracy: 0.2321 - val_loss: 1.8336 - val_accuracy: 0.3380\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.8837 - accuracy: 0.3149 - val_loss: 1.7684 - val_accuracy: 0.3714\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.8232 - accuracy: 0.3365 - val_loss: 1.7084 - val_accuracy: 0.3839\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.7940 - accuracy: 0.3504 - val_loss: 1.6694 - val_accuracy: 0.4088\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.7615 - accuracy: 0.3632 - val_loss: 1.6345 - val_accuracy: 0.4146\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.7359 - accuracy: 0.3704 - val_loss: 1.6636 - val_accuracy: 0.4184\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7257 - accuracy: 0.3765 - val_loss: 1.6575 - val_accuracy: 0.4048\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6954 - accuracy: 0.3883 - val_loss: 1.6066 - val_accuracy: 0.4395\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6820 - accuracy: 0.3936 - val_loss: 1.6047 - val_accuracy: 0.4349\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6695 - accuracy: 0.3989 - val_loss: 1.5774 - val_accuracy: 0.4374\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6574 - accuracy: 0.4014 - val_loss: 1.5773 - val_accuracy: 0.4506\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6479 - accuracy: 0.4074 - val_loss: 1.5806 - val_accuracy: 0.4493\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6380 - accuracy: 0.4087 - val_loss: 1.5424 - val_accuracy: 0.4529\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6336 - accuracy: 0.4116 - val_loss: 1.5354 - val_accuracy: 0.4511\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6195 - accuracy: 0.4180 - val_loss: 1.5500 - val_accuracy: 0.4558\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.6216 - accuracy: 0.4181 - val_loss: 1.5833 - val_accuracy: 0.4280\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5993 - accuracy: 0.4256 - val_loss: 1.5215 - val_accuracy: 0.4621\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5956 - accuracy: 0.4265 - val_loss: 1.5262 - val_accuracy: 0.4628\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.5943 - accuracy: 0.4254 - val_loss: 1.5076 - val_accuracy: 0.4795\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5772 - accuracy: 0.4332 - val_loss: 1.5107 - val_accuracy: 0.4682\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 43.9984 - accuracy: 0.1104 - val_loss: 4.4378 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4287 - accuracy: 0.0971 - val_loss: 4.4344 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4288 - accuracy: 0.0980 - val_loss: 4.4281 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4287 - accuracy: 0.0998 - val_loss: 4.4262 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4290 - accuracy: 0.1001 - val_loss: 4.4273 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4284 - accuracy: 0.0990 - val_loss: 4.4326 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4289 - accuracy: 0.0962 - val_loss: 4.4463 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4285 - accuracy: 0.0981 - val_loss: 4.4327 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4287 - accuracy: 0.0992 - val_loss: 4.4326 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4286 - accuracy: 0.0970 - val_loss: 4.4340 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4288 - accuracy: 0.0989 - val_loss: 4.4293 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4283 - accuracy: 0.0978 - val_loss: 4.4352 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4289 - accuracy: 0.0983 - val_loss: 4.4282 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4286 - accuracy: 0.0976 - val_loss: 4.4279 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4285 - accuracy: 0.0992 - val_loss: 4.4292 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 4.4287 - accuracy: 0.0968 - val_loss: 4.4379 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4284 - accuracy: 0.0971 - val_loss: 4.4334 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4286 - accuracy: 0.0960 - val_loss: 4.4367 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4285 - accuracy: 0.0979 - val_loss: 4.4250 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4287 - accuracy: 0.0979 - val_loss: 4.4354 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 3.9331 - accuracy: 0.2678 - val_loss: 2.6561 - val_accuracy: 0.3671\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.4174 - accuracy: 0.3487 - val_loss: 2.1756 - val_accuracy: 0.3914\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1693 - accuracy: 0.3726 - val_loss: 2.0537 - val_accuracy: 0.3984\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0636 - accuracy: 0.3832 - val_loss: 1.9621 - val_accuracy: 0.4241\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9897 - accuracy: 0.3939 - val_loss: 1.9053 - val_accuracy: 0.4239\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9419 - accuracy: 0.4028 - val_loss: 1.8834 - val_accuracy: 0.4186\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8980 - accuracy: 0.4101 - val_loss: 1.7872 - val_accuracy: 0.4506\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8761 - accuracy: 0.4111 - val_loss: 1.8301 - val_accuracy: 0.4339\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8403 - accuracy: 0.4203 - val_loss: 1.7798 - val_accuracy: 0.4448\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8162 - accuracy: 0.4253 - val_loss: 1.7731 - val_accuracy: 0.4455\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8097 - accuracy: 0.4261 - val_loss: 1.7396 - val_accuracy: 0.4566\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7873 - accuracy: 0.4329 - val_loss: 1.7133 - val_accuracy: 0.4637\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7864 - accuracy: 0.4323 - val_loss: 1.7444 - val_accuracy: 0.4494\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7753 - accuracy: 0.4333 - val_loss: 1.7136 - val_accuracy: 0.4615\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7710 - accuracy: 0.4374 - val_loss: 1.7138 - val_accuracy: 0.4679\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7601 - accuracy: 0.4423 - val_loss: 1.7487 - val_accuracy: 0.4480\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7556 - accuracy: 0.4419 - val_loss: 1.7251 - val_accuracy: 0.4540\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7502 - accuracy: 0.4464 - val_loss: 1.6944 - val_accuracy: 0.4620\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7479 - accuracy: 0.4449 - val_loss: 1.6916 - val_accuracy: 0.4646\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7320 - accuracy: 0.4472 - val_loss: 1.6939 - val_accuracy: 0.4580\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 2.0123 - accuracy: 0.2681 - val_loss: 1.8018 - val_accuracy: 0.3508\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.7780 - accuracy: 0.3576 - val_loss: 1.6634 - val_accuracy: 0.4056\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.7025 - accuracy: 0.3860 - val_loss: 1.6204 - val_accuracy: 0.4216\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.6573 - accuracy: 0.4070 - val_loss: 1.5794 - val_accuracy: 0.4373\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.6078 - accuracy: 0.4245 - val_loss: 1.5280 - val_accuracy: 0.4617\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5745 - accuracy: 0.4363 - val_loss: 1.5199 - val_accuracy: 0.4581\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5526 - accuracy: 0.4422 - val_loss: 1.5267 - val_accuracy: 0.4486\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5297 - accuracy: 0.4524 - val_loss: 1.4828 - val_accuracy: 0.4673\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5003 - accuracy: 0.4637 - val_loss: 1.4719 - val_accuracy: 0.4834\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4886 - accuracy: 0.4685 - val_loss: 1.4462 - val_accuracy: 0.4862\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4709 - accuracy: 0.4760 - val_loss: 1.4421 - val_accuracy: 0.4887\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4510 - accuracy: 0.4800 - val_loss: 1.4260 - val_accuracy: 0.4899\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4370 - accuracy: 0.4884 - val_loss: 1.4307 - val_accuracy: 0.4897\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4219 - accuracy: 0.4913 - val_loss: 1.4224 - val_accuracy: 0.4901\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4054 - accuracy: 0.4970 - val_loss: 1.4509 - val_accuracy: 0.4814\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4052 - accuracy: 0.4987 - val_loss: 1.3947 - val_accuracy: 0.5046\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.3914 - accuracy: 0.5018 - val_loss: 1.3956 - val_accuracy: 0.5011\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.3825 - accuracy: 0.5043 - val_loss: 1.3933 - val_accuracy: 0.5016\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.3653 - accuracy: 0.5119 - val_loss: 1.3666 - val_accuracy: 0.5091\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.3576 - accuracy: 0.5127 - val_loss: 1.3624 - val_accuracy: 0.5176\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.7860 - accuracy: 0.2472 - val_loss: 2.3315 - val_accuracy: 0.3343\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1992 - accuracy: 0.3148 - val_loss: 2.0762 - val_accuracy: 0.3344\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0406 - accuracy: 0.3324 - val_loss: 1.9570 - val_accuracy: 0.3570\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9709 - accuracy: 0.3459 - val_loss: 1.8973 - val_accuracy: 0.3759\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9544 - accuracy: 0.3470 - val_loss: 1.9068 - val_accuracy: 0.3664\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9428 - accuracy: 0.3464 - val_loss: 1.9566 - val_accuracy: 0.3372\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9261 - accuracy: 0.3523 - val_loss: 1.8720 - val_accuracy: 0.3675\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9155 - accuracy: 0.3566 - val_loss: 1.8593 - val_accuracy: 0.3869\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9077 - accuracy: 0.3571 - val_loss: 1.8746 - val_accuracy: 0.3656\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9000 - accuracy: 0.3611 - val_loss: 1.9283 - val_accuracy: 0.3518\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8988 - accuracy: 0.3595 - val_loss: 1.8679 - val_accuracy: 0.3688\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8867 - accuracy: 0.3662 - val_loss: 1.8465 - val_accuracy: 0.3660\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8845 - accuracy: 0.3645 - val_loss: 1.8783 - val_accuracy: 0.3635\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8690 - accuracy: 0.3713 - val_loss: 1.7981 - val_accuracy: 0.4017\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8797 - accuracy: 0.3666 - val_loss: 1.7998 - val_accuracy: 0.4069\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8612 - accuracy: 0.3702 - val_loss: 1.8536 - val_accuracy: 0.3786\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8802 - accuracy: 0.3675 - val_loss: 1.8051 - val_accuracy: 0.4008\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8760 - accuracy: 0.3678 - val_loss: 1.8162 - val_accuracy: 0.3871\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8629 - accuracy: 0.3734 - val_loss: 1.8197 - val_accuracy: 0.3807\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8601 - accuracy: 0.3721 - val_loss: 1.8511 - val_accuracy: 0.3735\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1043 - accuracy: 0.2724 - val_loss: 1.8961 - val_accuracy: 0.3488\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.8574 - accuracy: 0.3583 - val_loss: 1.7658 - val_accuracy: 0.3871\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7726 - accuracy: 0.3872 - val_loss: 1.7140 - val_accuracy: 0.4073\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7055 - accuracy: 0.4107 - val_loss: 1.6276 - val_accuracy: 0.4399\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6597 - accuracy: 0.4252 - val_loss: 1.5663 - val_accuracy: 0.4645\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6197 - accuracy: 0.4360 - val_loss: 1.5668 - val_accuracy: 0.4707\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5930 - accuracy: 0.4477 - val_loss: 1.5518 - val_accuracy: 0.4624\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5735 - accuracy: 0.4544 - val_loss: 1.5183 - val_accuracy: 0.4784\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.5586 - accuracy: 0.4597 - val_loss: 1.5174 - val_accuracy: 0.4809\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5239 - accuracy: 0.4713 - val_loss: 1.4892 - val_accuracy: 0.4838\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5210 - accuracy: 0.4724 - val_loss: 1.4767 - val_accuracy: 0.4874\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4947 - accuracy: 0.4834 - val_loss: 1.4718 - val_accuracy: 0.4873\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4838 - accuracy: 0.4826 - val_loss: 1.4468 - val_accuracy: 0.5040\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.4706 - accuracy: 0.4917 - val_loss: 1.5066 - val_accuracy: 0.4807\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4674 - accuracy: 0.4934 - val_loss: 1.4487 - val_accuracy: 0.5028\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4543 - accuracy: 0.4976 - val_loss: 1.4388 - val_accuracy: 0.5097\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4404 - accuracy: 0.5048 - val_loss: 1.4533 - val_accuracy: 0.4958\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4252 - accuracy: 0.5076 - val_loss: 1.4392 - val_accuracy: 0.5047\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 1.4096 - accuracy: 0.5168 - val_loss: 1.4346 - val_accuracy: 0.5080\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4146 - accuracy: 0.5140 - val_loss: 1.4341 - val_accuracy: 0.5053\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.1, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 1.9838 - accuracy: 0.2738 - val_loss: 1.8017 - val_accuracy: 0.3567\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.7779 - accuracy: 0.3590 - val_loss: 1.6718 - val_accuracy: 0.4063\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6969 - accuracy: 0.3936 - val_loss: 1.6262 - val_accuracy: 0.4215\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6504 - accuracy: 0.4097 - val_loss: 1.5733 - val_accuracy: 0.4385\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.6095 - accuracy: 0.4258 - val_loss: 1.5349 - val_accuracy: 0.4486\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5633 - accuracy: 0.4396 - val_loss: 1.5339 - val_accuracy: 0.4554\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.5436 - accuracy: 0.4487 - val_loss: 1.5013 - val_accuracy: 0.4628\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.5280 - accuracy: 0.4524 - val_loss: 1.4774 - val_accuracy: 0.4771\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4964 - accuracy: 0.4639 - val_loss: 1.4645 - val_accuracy: 0.4802\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4754 - accuracy: 0.4706 - val_loss: 1.4915 - val_accuracy: 0.4697\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4666 - accuracy: 0.4741 - val_loss: 1.4299 - val_accuracy: 0.4903\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4394 - accuracy: 0.4816 - val_loss: 1.4562 - val_accuracy: 0.4816\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4287 - accuracy: 0.4895 - val_loss: 1.4147 - val_accuracy: 0.4983\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4130 - accuracy: 0.4925 - val_loss: 1.4433 - val_accuracy: 0.4812\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.4093 - accuracy: 0.4959 - val_loss: 1.4259 - val_accuracy: 0.4905\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.3910 - accuracy: 0.5012 - val_loss: 1.3891 - val_accuracy: 0.5064\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.3758 - accuracy: 0.5066 - val_loss: 1.4240 - val_accuracy: 0.4859\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.3592 - accuracy: 0.5104 - val_loss: 1.3886 - val_accuracy: 0.5075\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.3525 - accuracy: 0.5152 - val_loss: 1.3903 - val_accuracy: 0.5085\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.3323 - accuracy: 0.5203 - val_loss: 1.3676 - val_accuracy: 0.5125\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 44.6365 - accuracy: 0.1004 - val_loss: 4.4525 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4472 - accuracy: 0.0988 - val_loss: 4.4526 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4487 - accuracy: 0.0979 - val_loss: 4.4533 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4492 - accuracy: 0.0990 - val_loss: 4.4456 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4501 - accuracy: 0.0972 - val_loss: 4.4485 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4492 - accuracy: 0.0981 - val_loss: 4.4537 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4503 - accuracy: 0.0966 - val_loss: 4.4643 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4498 - accuracy: 0.0986 - val_loss: 4.4542 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4500 - accuracy: 0.0971 - val_loss: 4.4591 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4501 - accuracy: 0.0957 - val_loss: 4.4543 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4503 - accuracy: 0.0975 - val_loss: 4.4487 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4498 - accuracy: 0.0983 - val_loss: 4.4622 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4504 - accuracy: 0.0964 - val_loss: 4.4466 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4503 - accuracy: 0.0980 - val_loss: 4.4523 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4499 - accuracy: 0.0978 - val_loss: 4.4515 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4504 - accuracy: 0.0989 - val_loss: 4.4592 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4501 - accuracy: 0.0965 - val_loss: 4.4524 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4501 - accuracy: 0.0975 - val_loss: 4.4615 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4502 - accuracy: 0.0969 - val_loss: 4.4444 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4505 - accuracy: 0.0982 - val_loss: 4.4592 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 4.1932 - accuracy: 0.1532 - val_loss: 2.8837 - val_accuracy: 0.2612\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.6814 - accuracy: 0.2005 - val_loss: 2.4625 - val_accuracy: 0.2685\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.4703 - accuracy: 0.2177 - val_loss: 2.3478 - val_accuracy: 0.2690\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3519 - accuracy: 0.2295 - val_loss: 2.2470 - val_accuracy: 0.2883\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2594 - accuracy: 0.2453 - val_loss: 2.2012 - val_accuracy: 0.2997\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2044 - accuracy: 0.2432 - val_loss: 2.0602 - val_accuracy: 0.3274\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1528 - accuracy: 0.2541 - val_loss: 2.0913 - val_accuracy: 0.3053\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1188 - accuracy: 0.2574 - val_loss: 2.0646 - val_accuracy: 0.3085\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0945 - accuracy: 0.2580 - val_loss: 2.0719 - val_accuracy: 0.3143\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0761 - accuracy: 0.2639 - val_loss: 2.0399 - val_accuracy: 0.2952\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0651 - accuracy: 0.2668 - val_loss: 2.0610 - val_accuracy: 0.3140\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0663 - accuracy: 0.2653 - val_loss: 2.0415 - val_accuracy: 0.2902\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0606 - accuracy: 0.2668 - val_loss: 2.0318 - val_accuracy: 0.3187\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0598 - accuracy: 0.2690 - val_loss: 2.0305 - val_accuracy: 0.3072\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0619 - accuracy: 0.2701 - val_loss: 2.0491 - val_accuracy: 0.3172\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 15ms/step - loss: 2.0513 - accuracy: 0.2732 - val_loss: 2.0623 - val_accuracy: 0.2997\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0529 - accuracy: 0.2697 - val_loss: 2.1146 - val_accuracy: 0.2738\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0550 - accuracy: 0.2733 - val_loss: 2.0415 - val_accuracy: 0.2972\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0515 - accuracy: 0.2699 - val_loss: 2.1321 - val_accuracy: 0.2813\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0529 - accuracy: 0.2716 - val_loss: 2.0481 - val_accuracy: 0.3047\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2213 - accuracy: 0.1600 - val_loss: 2.0348 - val_accuracy: 0.2561\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0966 - accuracy: 0.1949 - val_loss: 2.0054 - val_accuracy: 0.2501\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0684 - accuracy: 0.2028 - val_loss: 2.0086 - val_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0443 - accuracy: 0.2137 - val_loss: 2.0079 - val_accuracy: 0.2743\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0289 - accuracy: 0.2243 - val_loss: 1.9795 - val_accuracy: 0.2713\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0136 - accuracy: 0.2275 - val_loss: 1.9887 - val_accuracy: 0.2652\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0034 - accuracy: 0.2311 - val_loss: 1.9951 - val_accuracy: 0.2661\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9999 - accuracy: 0.2364 - val_loss: 2.0096 - val_accuracy: 0.2678\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9939 - accuracy: 0.2371 - val_loss: 1.9685 - val_accuracy: 0.2727\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9938 - accuracy: 0.2376 - val_loss: 2.0092 - val_accuracy: 0.2570\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9933 - accuracy: 0.2373 - val_loss: 2.0195 - val_accuracy: 0.2739\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9891 - accuracy: 0.2384 - val_loss: 1.9525 - val_accuracy: 0.2912\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9837 - accuracy: 0.2401 - val_loss: 2.0290 - val_accuracy: 0.2664\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9853 - accuracy: 0.2428 - val_loss: 1.9950 - val_accuracy: 0.2664\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9784 - accuracy: 0.2425 - val_loss: 2.0320 - val_accuracy: 0.2416\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9786 - accuracy: 0.2438 - val_loss: 1.9605 - val_accuracy: 0.2673\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9758 - accuracy: 0.2462 - val_loss: 2.0214 - val_accuracy: 0.2642\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9854 - accuracy: 0.2441 - val_loss: 1.9912 - val_accuracy: 0.2781\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9734 - accuracy: 0.2467 - val_loss: 1.9948 - val_accuracy: 0.2650\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9729 - accuracy: 0.2466 - val_loss: 1.9719 - val_accuracy: 0.2720\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 5.0119 - accuracy: 0.1600 - val_loss: 2.2777 - val_accuracy: 0.2597\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2179 - accuracy: 0.2202 - val_loss: 2.1088 - val_accuracy: 0.2476\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1417 - accuracy: 0.2309 - val_loss: 2.0622 - val_accuracy: 0.2495\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1335 - accuracy: 0.2293 - val_loss: 2.0707 - val_accuracy: 0.2529\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1264 - accuracy: 0.2209 - val_loss: 2.0122 - val_accuracy: 0.2859\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1212 - accuracy: 0.2245 - val_loss: 2.0524 - val_accuracy: 0.2529\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1201 - accuracy: 0.2241 - val_loss: 2.0327 - val_accuracy: 0.2725\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1204 - accuracy: 0.2168 - val_loss: 2.0620 - val_accuracy: 0.2656\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1149 - accuracy: 0.2212 - val_loss: 2.0100 - val_accuracy: 0.2633\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1122 - accuracy: 0.2207 - val_loss: 2.0290 - val_accuracy: 0.2591\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1146 - accuracy: 0.2187 - val_loss: 2.0436 - val_accuracy: 0.2614\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1067 - accuracy: 0.2209 - val_loss: 2.0142 - val_accuracy: 0.2701\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0992 - accuracy: 0.2217 - val_loss: 2.0341 - val_accuracy: 0.2555\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1009 - accuracy: 0.2200 - val_loss: 2.0592 - val_accuracy: 0.2286\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1044 - accuracy: 0.2213 - val_loss: 2.0466 - val_accuracy: 0.2553\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0954 - accuracy: 0.2234 - val_loss: 2.0093 - val_accuracy: 0.2771\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0972 - accuracy: 0.2253 - val_loss: 2.0623 - val_accuracy: 0.2563\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1140 - accuracy: 0.2161 - val_loss: 2.0416 - val_accuracy: 0.2696\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0904 - accuracy: 0.2277 - val_loss: 2.0217 - val_accuracy: 0.2648\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0972 - accuracy: 0.2268 - val_loss: 2.0318 - val_accuracy: 0.2655\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.3434 - accuracy: 0.1543 - val_loss: 2.1392 - val_accuracy: 0.2456\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.1717 - accuracy: 0.2046 - val_loss: 2.0701 - val_accuracy: 0.2722\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.1121 - accuracy: 0.2171 - val_loss: 2.0567 - val_accuracy: 0.2806\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0773 - accuracy: 0.2296 - val_loss: 2.0322 - val_accuracy: 0.2999\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0491 - accuracy: 0.2377 - val_loss: 2.0328 - val_accuracy: 0.2966\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0333 - accuracy: 0.2422 - val_loss: 2.0186 - val_accuracy: 0.2901\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0185 - accuracy: 0.2468 - val_loss: 2.0173 - val_accuracy: 0.2951\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 4s 18ms/step - loss: 2.0080 - accuracy: 0.2509 - val_loss: 2.0014 - val_accuracy: 0.2994\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9893 - accuracy: 0.2562 - val_loss: 1.9679 - val_accuracy: 0.3087\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9860 - accuracy: 0.2609 - val_loss: 1.9917 - val_accuracy: 0.3107\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9804 - accuracy: 0.2612 - val_loss: 1.9812 - val_accuracy: 0.3053\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9784 - accuracy: 0.2599 - val_loss: 1.9673 - val_accuracy: 0.2952\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9673 - accuracy: 0.2687 - val_loss: 1.9877 - val_accuracy: 0.2789\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9697 - accuracy: 0.2656 - val_loss: 1.9361 - val_accuracy: 0.3002\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9589 - accuracy: 0.2702 - val_loss: 1.9700 - val_accuracy: 0.2964\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9630 - accuracy: 0.2686 - val_loss: 1.9363 - val_accuracy: 0.3304\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9572 - accuracy: 0.2721 - val_loss: 1.9443 - val_accuracy: 0.2947\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9520 - accuracy: 0.2732 - val_loss: 1.9815 - val_accuracy: 0.2881\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9494 - accuracy: 0.2748 - val_loss: 1.9617 - val_accuracy: 0.3061\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9481 - accuracy: 0.2775 - val_loss: 1.9883 - val_accuracy: 0.3028\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.5, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.2135 - accuracy: 0.1590 - val_loss: 2.0971 - val_accuracy: 0.2406\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0864 - accuracy: 0.1959 - val_loss: 2.0389 - val_accuracy: 0.2577\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0476 - accuracy: 0.2162 - val_loss: 2.0004 - val_accuracy: 0.2645\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0295 - accuracy: 0.2250 - val_loss: 1.9967 - val_accuracy: 0.2908\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0210 - accuracy: 0.2287 - val_loss: 2.0168 - val_accuracy: 0.2533\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0153 - accuracy: 0.2313 - val_loss: 1.9947 - val_accuracy: 0.2821\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.0099 - accuracy: 0.2356 - val_loss: 1.9546 - val_accuracy: 0.2917\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.0028 - accuracy: 0.2398 - val_loss: 1.9772 - val_accuracy: 0.2782\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9951 - accuracy: 0.2446 - val_loss: 1.9595 - val_accuracy: 0.2753\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9931 - accuracy: 0.2432 - val_loss: 1.9685 - val_accuracy: 0.2766\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9849 - accuracy: 0.2501 - val_loss: 1.9810 - val_accuracy: 0.2837\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9754 - accuracy: 0.2540 - val_loss: 1.9689 - val_accuracy: 0.2720\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9671 - accuracy: 0.2574 - val_loss: 1.9408 - val_accuracy: 0.2898\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9618 - accuracy: 0.2608 - val_loss: 1.9684 - val_accuracy: 0.2769\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9586 - accuracy: 0.2597 - val_loss: 1.9714 - val_accuracy: 0.2813\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9551 - accuracy: 0.2598 - val_loss: 1.9562 - val_accuracy: 0.2834\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 1.9462 - accuracy: 0.2684 - val_loss: 1.9463 - val_accuracy: 0.2837\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9468 - accuracy: 0.2650 - val_loss: 1.9614 - val_accuracy: 0.2784\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9418 - accuracy: 0.2677 - val_loss: 1.9422 - val_accuracy: 0.2965\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 1.9447 - accuracy: 0.2660 - val_loss: 1.9636 - val_accuracy: 0.2848\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 47.7921 - accuracy: 0.0992 - val_loss: 4.4421 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4360 - accuracy: 0.0980 - val_loss: 4.4386 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4406 - accuracy: 0.0983 - val_loss: 4.4433 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 4.4429 - accuracy: 0.0958 - val_loss: 4.4437 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4441 - accuracy: 0.0984 - val_loss: 4.4497 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4444 - accuracy: 0.0990 - val_loss: 4.4450 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4453 - accuracy: 0.0962 - val_loss: 4.4556 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4453 - accuracy: 0.0987 - val_loss: 4.4483 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4457 - accuracy: 0.0981 - val_loss: 4.4517 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4460 - accuracy: 0.0979 - val_loss: 4.4524 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4461 - accuracy: 0.0973 - val_loss: 4.4496 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4459 - accuracy: 0.0971 - val_loss: 4.4503 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4466 - accuracy: 0.0988 - val_loss: 4.4431 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4460 - accuracy: 0.0975 - val_loss: 4.4518 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4463 - accuracy: 0.0977 - val_loss: 4.4467 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4464 - accuracy: 0.0966 - val_loss: 4.4569 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4463 - accuracy: 0.0967 - val_loss: 4.4484 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4463 - accuracy: 0.0986 - val_loss: 4.4500 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4465 - accuracy: 0.0974 - val_loss: 4.4419 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 4.4464 - accuracy: 0.0968 - val_loss: 4.4556 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 16ms/step - loss: 4.9613 - accuracy: 0.1028 - val_loss: 3.8537 - val_accuracy: 0.1480\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 3.3305 - accuracy: 0.1353 - val_loss: 2.9012 - val_accuracy: 0.1760\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.7212 - accuracy: 0.1466 - val_loss: 2.5453 - val_accuracy: 0.1860\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.5111 - accuracy: 0.1585 - val_loss: 2.4208 - val_accuracy: 0.1852\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.4186 - accuracy: 0.1623 - val_loss: 2.4464 - val_accuracy: 0.1222\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3312 - accuracy: 0.1671 - val_loss: 2.3515 - val_accuracy: 0.1495\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2872 - accuracy: 0.1695 - val_loss: 2.3260 - val_accuracy: 0.1398\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2518 - accuracy: 0.1721 - val_loss: 2.3233 - val_accuracy: 0.1310\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2297 - accuracy: 0.1717 - val_loss: 2.2950 - val_accuracy: 0.1468\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2234 - accuracy: 0.1729 - val_loss: 2.3193 - val_accuracy: 0.1259\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2063 - accuracy: 0.1750 - val_loss: 2.2326 - val_accuracy: 0.1695\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2100 - accuracy: 0.1762 - val_loss: 2.2989 - val_accuracy: 0.1271\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1869 - accuracy: 0.1819 - val_loss: 2.2497 - val_accuracy: 0.1754\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2016 - accuracy: 0.1796 - val_loss: 2.2615 - val_accuracy: 0.1719\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1895 - accuracy: 0.1857 - val_loss: 2.2421 - val_accuracy: 0.1697\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1879 - accuracy: 0.1883 - val_loss: 2.2364 - val_accuracy: 0.1646\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1830 - accuracy: 0.1894 - val_loss: 2.2783 - val_accuracy: 0.1511\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1872 - accuracy: 0.1897 - val_loss: 2.2267 - val_accuracy: 0.1972\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1835 - accuracy: 0.1926 - val_loss: 2.2859 - val_accuracy: 0.1573\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.1829 - accuracy: 0.1913 - val_loss: 2.2397 - val_accuracy: 0.1822\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L1'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3574 - accuracy: 0.0999 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0991 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3031 - accuracy: 0.0998 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3035 - accuracy: 0.0992 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0995 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3032 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0986 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0972 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.1021 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3032 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0983 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.0963 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3034 - accuracy: 0.0988 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3032 - accuracy: 0.0970 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3030 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3031 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3030 - accuracy: 0.0984 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.01\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 6.4406 - accuracy: 0.1119 - val_loss: 2.8146 - val_accuracy: 0.1381\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.4680 - accuracy: 0.1474 - val_loss: 2.2530 - val_accuracy: 0.1630\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2620 - accuracy: 0.1557 - val_loss: 2.2183 - val_accuracy: 0.1741\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2353 - accuracy: 0.1576 - val_loss: 2.2129 - val_accuracy: 0.1734\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2234 - accuracy: 0.1566 - val_loss: 2.1669 - val_accuracy: 0.1900\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2085 - accuracy: 0.1597 - val_loss: 2.1679 - val_accuracy: 0.1931\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2051 - accuracy: 0.1645 - val_loss: 2.1800 - val_accuracy: 0.1777\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2200 - accuracy: 0.1585 - val_loss: 2.1814 - val_accuracy: 0.1798\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2110 - accuracy: 0.1621 - val_loss: 2.2334 - val_accuracy: 0.1495\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2143 - accuracy: 0.1600 - val_loss: 2.1893 - val_accuracy: 0.1789\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2013 - accuracy: 0.1666 - val_loss: 2.2156 - val_accuracy: 0.1591\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.2104 - accuracy: 0.1636 - val_loss: 2.1703 - val_accuracy: 0.1866\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.1978 - accuracy: 0.1646 - val_loss: 2.1814 - val_accuracy: 0.1780\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2022 - accuracy: 0.1644 - val_loss: 2.1761 - val_accuracy: 0.1814\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.1994 - accuracy: 0.1667 - val_loss: 2.1815 - val_accuracy: 0.1778\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2122 - accuracy: 0.1608 - val_loss: 2.2029 - val_accuracy: 0.1652\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2083 - accuracy: 0.1624 - val_loss: 2.1753 - val_accuracy: 0.1804\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2110 - accuracy: 0.1586 - val_loss: 2.2236 - val_accuracy: 0.1540\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.2068 - accuracy: 0.1615 - val_loss: 2.2198 - val_accuracy: 0.1590\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 2.2111 - accuracy: 0.1610 - val_loss: 2.2034 - val_accuracy: 0.1735\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=0.0001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 2.4885 - accuracy: 0.0981 - val_loss: 2.4181 - val_accuracy: 0.0999\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.4091 - accuracy: 0.0975 - val_loss: 2.4001 - val_accuracy: 0.1004\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3928 - accuracy: 0.0975 - val_loss: 2.3851 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3787 - accuracy: 0.0987 - val_loss: 2.3721 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3664 - accuracy: 0.0963 - val_loss: 2.3607 - val_accuracy: 0.1001\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3558 - accuracy: 0.0984 - val_loss: 2.3508 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3466 - accuracy: 0.0955 - val_loss: 2.3422 - val_accuracy: 0.1014\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3386 - accuracy: 0.0974 - val_loss: 2.3351 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3321 - accuracy: 0.0974 - val_loss: 2.3290 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3264 - accuracy: 0.0990 - val_loss: 2.3238 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3216 - accuracy: 0.0977 - val_loss: 2.3194 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3177 - accuracy: 0.0990 - val_loss: 2.3159 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3144 - accuracy: 0.0989 - val_loss: 2.3130 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3118 - accuracy: 0.0976 - val_loss: 2.3106 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3097 - accuracy: 0.0967 - val_loss: 2.3088 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3081 - accuracy: 0.0989 - val_loss: 2.3073 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3068 - accuracy: 0.0967 - val_loss: 2.3061 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3057 - accuracy: 0.0970 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3050 - accuracy: 0.0976 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 16ms/step - loss: 2.3044 - accuracy: 0.0972 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Experiment with Batch_size = 256, Drop_ratio = 0.7, Regularizer_Function=<class 'keras.regularizers.L2'>, Regularizer_Ratio=1e-08\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 4s 17ms/step - loss: 2.3564 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1001\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3030 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3031 - accuracy: 0.1015 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1001\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1020\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 3s 18ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 4s 19ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 3s 17ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "\n",
    "for batch_size,drop_ratio,reg_fun,reg_ratio in itertools.product(Batch_size, Drop_ratio, Regularizer_Function, Regularizer_Ratio):\n",
    "    keras.backend.clear_session()\n",
    "    print(f'Experiment with Batch_size = {batch_size}, Drop_ratio = {drop_ratio}, Regularizer_Function={reg_fun}, Regularizer_Ratio={reg_ratio}')\n",
    "    model = build_mlp(input_shape=x_train.shape[1:], drop_ratio = drop_ratio, regularizer = reg_fun, regularizer_ratio = reg_ratio)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam(lr = LEARNING_RATE)\n",
    "    model.compile(loss = 'categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train,y_train,\n",
    "              epochs = EPOCHS,\n",
    "              batch_size = batch_size,\n",
    "              validation_data = (x_test, y_test),\n",
    "              shuffle = True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history['loss']\n",
    "    valid_loss = model.history.history['val_loss']\n",
    "    train_acc = model.history.history['accuracy']\n",
    "    valid_acc = model.history.history['val_accuracy']\n",
    "\n",
    "    exp_name_tag = f'batch_size-{batch_size}-drop_ratio-{drop_ratio}-reg_fun-{reg_fun}-reg_ratio-{reg_ratio}'\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc' : train_acc,\n",
    "                             'val-acc'   : valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21920/1341050420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm as mplcm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "\n",
    "NUM_COLORS = 20\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['val-acc'])),results[cond]['val-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([\"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-32-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-128-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.25-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.1-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.5-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L1'>-reg_ratio-1e-08\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.01\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-0.0001\", \"batch_size-256-drop_ratio-0.7-reg_fun-<class 'keras.regularizers.L2'>-reg_ratio-1e-08\"])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
